{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TyqwIyCh1ZxY"
   },
   "source": [
    "# **Tâche #2 - Questions-réponses avec un modèle QA extractif**\n",
    "\n",
    "Cette tâche consiste à utiliser un modèle de question-réponse extractif de type transformer afin de repérer des informations dans un texte. Vous utilisez la librairie HuggingFace pour accomplir cette tâche. On demande plus spécifiquement d’utiliser le modèle *bert-base-uncased-whole-word-masking-finetuned-squad*.\n",
    "\n",
    "La tâche a pour but précis de repérer 3 informations dans les descriptions textuelles : le lieu et la date de l’incident ainsi qu’un court passage de texte indiquant ce qui s’est passé.  Une partie importante de votre travail consiste à trouver de bonnes formulations de questions pour repérer ces informations. Le fichier *t2_qa_examples*.json, qui contient 25 exemples annotés par un humain, est disponible pour mener vos expérimentations.\n",
    "\n",
    "Les consignes pour cette tâche sont:\n",
    "-\tNom du notebook : *t2_qa.ipynb* (ce notebook)\n",
    "-\tTokenisation et plongements de mots : Ceux du modèle utilisé.\n",
    "-\tNormalisation : Aucune normalisation à faire (le tokeniseur convertit les lettres en minuscule).\n",
    "-\tConstruction du modèle : vous utilisez la version préentraînée du modèle sans modification. Aucun affinement (fine-tuning) du modèle n’est requis pour cette tâche.\n",
    "-\tÉvaluation : Du code est disponible dans le notebook pour évaluer la performance du modèle avec les métriques *exact match* et *F1*.\n",
    "-\tAnalyse : Présentez et discutez des résultats que vous obtenez pour les 3 types d’informations à repérer. Discutez également de vos choix de questions pour accomplir cette tâche et les erreurs commises par le modèle QA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4U3Dg2p47_R"
   },
   "source": [
    "Vous pouvez ajouter au notebook toutes les cellules dont vous avez besoin pour votre code, vos explications ou la présentation de vos résultats. Vous pouvez également ajouter des sous-sections (par ex. des sous-sections 1.1, 1.2 etc.) si cela améliore la lisibilité.\n",
    "\n",
    "Notes :\n",
    "- Évitez les bouts de code trop longs ou trop complexes. Par exemple, il est difficile de comprendre 4-5 boucles ou conditions imbriquées. Si c'est le cas, définissez des sous-fonctions pour refactoriser et simplifier votre code.\n",
    "- Expliquez sommairement votre démarche.\n",
    "- Expliquez les choix que vous faites au niveau de la programmation et des modèles (si non trivial).\n",
    "- Analysez vos résultats. Indiquez ce que vous observez, si c'est bon ou non, si c'est surprenant, etc.\n",
    "- Une analyse quantitative et qualitative d'erreurs est intéressante et permet de mieux comprendre le comportement d'un modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I-EMnvr-5k-3"
   },
   "source": [
    "## 1. Le chargement des données\n",
    "\n",
    "Utilisez le fichier ***/data/t2_qa_examples.json*** pour mener vos expérimentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "S_YxKHYm5k-3"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_json_data(filename):\n",
    "    with open(filename, 'r') as fp:\n",
    "        data = json.load(fp)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jE2CSpS25k-3"
   },
   "outputs": [],
   "source": [
    "data = load_json_data('/data/t2_qa_examples.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vqdc8aEWFvi3",
    "outputId": "30145881-2a71-45ee-d0d2-dbc87be52bdf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': ' At around 10:00 p.m. on November 10  2013  Employee #1  with Villager  Construction Inc.  with a coworker  were using an asphalt milling machine  (Wirtgen; Model Number: W2100) to grind out existing asphalt from an  interstate at a railroad bridge overpass. Employee # 1 was standing on the  ground  checking the depth of the cut into the asphalt  using a handheld  pendant attached to the machine. The pedant could stretch out from ten to 15  ft. This allowed Employee #1 to walk back and forth  checking the cut. The  operator was on the top of the milling machine  controlling the operation of  the machine and ensuring that the milling machine and dump truck (driven by a  second coworker  who worked for an independent trucking service) kept a safe  working distance. A different company  Protective Services Inc. (PSI)  was  responsible for the traffic control of the job site and had shut down the  inside lane of a three lane section of the interstate  so that work could be  conducted on that lane. The entire work zone was approximately two miles long   from start to finish. Employee #1 and the operator of the milling machine had  completed milling four sections (eight total passes) of the inside lane at the  bridge overpasses and were waiting for PSI to shut down the center lane. Dual  lane shut down of the inside and center lanes of the interstate was completed  around 9:30 p.m.  and Employee #1 and the milling machine operator milled two  sections (four total passes) of the center lane. Once both sides of the  overpass were milled out  approximately 200 ft on each side  Employee #1 and  the operator of the milling machine moved the milling machine down the  interstate  approximately1 000 ft  to a railroad overpass and began setting up  to mill the center lane sections. The truck driver backed his truck into  position and remained in the truck to move the truck slowly forward as milling  took place. Employee #1 was positioned between the milling machine and the  concrete median dividers  inside the coned off work zone. The lanes of travel  were approximately 12 ft wide  so the milling machine made two passes  since  it can only cut seven ft wide on each section to cover the entire lane.  Employee #1 was standing approximately three ft in the far inside lane on the  ground between milling machine and interior median wall inside of the approved  traffic control set up  and approximately midway up the machine and 17 ft from  the traffic control devices and flow of traffic. The milling machine was  approximately nine ft wide by 50 ft long  while operating. Employee #1 was  guarded by the machine from the flow of traffic. Approximately five to ten  minutes into the first pass  the milling machine operator noticed lights  hitting the reflectors on the inside wall and turned briefly to see a vehicle  coming. The operator thought it was the Project manager coming to check on the  status of the project. Then  the operator realized that the oncoming vehicle  was not equipped with a strobe  as required in work zones. The operator turned  and yelled for Employee # 1 to run for safety  as a Chevrolet Tahoe came down  the inside lane where Employee #1 was standing. The driver of the Tahoe  continued traveling in the far inside lane of the work zone  where Employee #1  was struck and thrown some 100 ft from where he was originally standing. The  vehicle was moving approximately 45 mph per hour. As he was transferred to a  hospital by emergency personnel  Employee #1 was treated for severe trauma   lacerations  fractures  and contusions to the body and head. Employee #1 was  pronounced dead at the hospital. The driver of the vehicle disregarded the  traffic control set up  all warning lights on the rear of the milling machine   and cone spacing of 100 ft. The construction work zone was set up correctly  with all signage  cone spacing  tapering  attenuators  and lighting; all of  the traffic control set up was approved by MUTCD for this type of tr ',\n",
       "  'WHEN': 'November 10  2013',\n",
       "  'WHERE': 'railroad bridge overpass',\n",
       "  'EVENT': 'Employee #1  was struck and thrown'},\n",
       " {'text': \" On August 27  2012  Employee #1  a 19 year-old male laborer with Stomper  Company Inc.  arrived at 2:00 .am. at a site in Menlo Park California to  demolish the interiors of the building. They scraped the interiors of the  building and collected debris as they finished up the job. On August 28  2012   at approximately 10:00 a.m  the job assignment was done and every employee was  to put away all the rubble and gather all equipment in order to pack up and  leave the site. When the job assignment was finished  it is typical for all  employees to gather everything and put it away into the garbage bin or in  their trailers and bins. At the time  four coworkers were outside in the  parking lot working near the Number 5 700 Panther. Two coworkers were going to  load the number 5 700 Panther and Employee #1 stated that he was going to load  the number 5 700 Panther on a trailer when their trailer returns from the trip  delivering their first load. This worker got on a Gradall machine to lift a  box bin and move it towards the number 5 700 Panther. The coworkers stated  that Employee #1  not the employee designated to drive the Panther  got on  this vehicle and started driving it. Employee #1 attempted to load a number  5 700 Panther on to a bin. This bin had a rubber lip with a four to five inch  incline ramp on its lip's edge. Employee #1 drove the Panther straight  backwards on the bin and did not go through this four to five inch ramp bump  on to the bin. Right after this unsuccessful attempt  Employee #1 drove it  backwards a second time except this time slightly slanted to his left side.  The left wheel touched the ramp first. On this second attempt  the number  5 700 Panther fell and flipped over. Employee #1 attempted to jump out of this  vehicle but was unable to get away as the Panther which weighed over 2 000  pounds fell on his left foot and pinned it. A coworker got the Gradall  machinery in order to remove the Panther that was on top of Employee #1's left  foot. Employee #1 suffered a serious fracture injury to his left leg and was  hospitalized over twenty-four hours. Employee #1 also stated that he is well  trained in driving other construction vehicle equipment by another foreman.     \",\n",
       "  'WHEN': 'August 27  2012',\n",
       "  'WHERE': 'Menlo Park California',\n",
       "  'EVENT': 'the Panther which weighed over 2 000  pounds fell on his left foot and pinned it'},\n",
       " {'text': ' On September 19  2012  Employee #1 had a seizure while utilizing a bathroom  facility. The employee has past history of seizures. A coworker found Employee  #1 unresponsive  and called 911 then performed CPR  on the employee until  paramedics arrived. Employee #1 was transported to St. James hospital in  Chicago Heights  where he was pronounced dead.                                  ',\n",
       "  'WHEN': 'September 19  2012',\n",
       "  'WHERE': 'a bathroom  facility',\n",
       "  'EVENT': 'Employee #1 had a seizure'},\n",
       " {'text': '   At approximately 9:30 a.m. on November17  2010  Employee #1 of Midwest  Masonry  Inc.  was responsible for using the cement mixer. He was struck by  the cement mixer that tipped over in the process of mixing cement/concrete.  Employee #1 suffered bruises to his upper right thigh and right hip. There was  no visible damage to the cement mixer. In addition  there were no employees to  observe how the cement mixer fell on the employee.                              ',\n",
       "  'WHEN': 'November17  2010',\n",
       "  'WHERE': 'mixing cement/concrete',\n",
       "  'EVENT': 'He was struck by  the cement mixer'},\n",
       " {'text': ' On September 26  2013  Employee #1  a \"flagger\" with Iowa Erosion Control   Inc.  was turning a vertical sign from STOP to SLOW  based upon the location  of a pilot car running between the worker\\'s location and a second coworker  \"flagger \" located approximately one mile away. A semi-truck came up over a  hill to the south of Employee #1. While traveling  its brakes locked up   leaving residue on the roadway. Then  the semi-truck swerved to miss a car at  Employee #1\\'s sign area and struck Employee #1. Employee #1 was then dragged  and/or rolled approximately 40 ft to the north  where his body came to rest.  The semi-truck veered into the ditch area at the north edge of the street and  then proceeded north. The Initial investigation revealed that warning signs  were posted along the highway  cones and other markings were present  and  Employee #1was wearing a high visibility vest/clothing. Employee #1 was killed  in the incident.                                                                ',\n",
       "  'WHEN': 'September 26  2013',\n",
       "  'WHERE': 'one mile away',\n",
       "  'EVENT': 'struck Employee #1'},\n",
       " {'text': ' On June 14  2011  Employee #1 was part of a road crew picking up and removing  a piece of traffic control equipment that was located on a trailer. The  equipment had been positioned in the emergency shoulder of an interstate  highway. A driver of a passenger vehicle fell asleep while driving and crossed  three lanes of traffic. The passenger vehicle struck the trailered equipment  and Employee #1. Employee #1 was killed.                                        ',\n",
       "  'WHEN': 'June 14  2011',\n",
       "  'WHERE': 'the emergency shoulder of an interstate  highway',\n",
       "  'EVENT': 'The passenger vehicle struck the trailered equipment and Employee #1'},\n",
       " {'text': ' On February 3  2011  a 34-year-old maintenance assistant employee was working  with a crew performing grouting and patching repairs inside a tunnel pipeline.  The employee moved  and his left foot was struck by and run over by a loader.  The employee underwent surgery for a crushed left foot.                         ',\n",
       "  'WHEN': 'February 3  2011',\n",
       "  'WHERE': 'inside a tunnel pipeline',\n",
       "  'EVENT': 'his left foot was struck by and run over by a loader'},\n",
       " {'text': ' At approximately 9:00 a.m. on February 6  2009  Employee #1 was a service  technician for Arbon Equipment. He was at Birds Eye Foods to service the dock  lock on Bay Number 3. He parked his service truck in front of Bay Number 3. A  tractor-trailer unit was parked in the adjacent bay and there was a gap of  approximately 2 to 3 ft between the trailer and the loading dock frame.  Employee #1 went to the front of the truck to look for the driver. He did not  see the driver so he walked to the back of the trailer and climbed on top of  the dock lock to examine it. The truck driver had been in the sleeper berth. A  dock worker notified the truck driver that he was not fully backed into place  at the loading dock. The driver backed up to close the gap  unaware that  Employee #1 was on the dock lock. Employee #1 fell off the dock lock and was  pinned between the loading dock and trailer. He suffered a fractured pelvis  a  ruptured bladder  and leg vein damage. He was hospitalized for treatment of  his injuries.                                                                   ',\n",
       "  'WHEN': 'February 6  2009',\n",
       "  'WHERE': 'Birds Eye Foods',\n",
       "  'EVENT': 'Employee #1 fell off the dock lock and was  pinned between the loading dock and trailer'},\n",
       " {'text': \" At 3:45 a.m. on September 29  2011  Employee #1  who was employed by Greene's   Inc.  was removing temporary traffic control barrels on Interstate 15 (I-15)  and approximately 14100 South. The company had been working on a stretch of  I-15 from the Utah County line to 12300 South in Salt Lake County. The  project  which had begun in May  was to replace damaged sections of the  Interstate  and the work was being conducted in the evenings. According to  witnesses  Employee #1 had begun removing the temporary traffic control  barrels at the north end of the northbound 14300 South on-ramp. The barrels  that were located at the south end of the on-ramp had been removed before it  was safe to allow traffic to use the on-ramp. A dump truck had entered the  on-ramp  and the driver of the dump truck did not know that workers were still  removing the barrels from the work site. Employee #1 had removed a barrel from  the interstate and had placed it on the east side of the on-ramp. He was  walking west across the on-ramp to remove another barrel and was struck by the  dump truck. Employee #1 was killed. Employee #1 was wearing a high-visibility  vest but the driver of the dump truck did not see him in time to stop.          \",\n",
       "  'WHEN': 'September 29  2011',\n",
       "  'WHERE': 'Interstate 15 (I-15)  and approximately 14100 South',\n",
       "  'EVENT': 'struck by the  dump truck'},\n",
       " {'text': \" On September 30  2008  Employee #1 and a coworker were installing a running  line in an Alimack hoist tower. While Employee #1 was located in the Alimack  hoist tower  the coworker was standing on top of a car feeding Employee #1 the  line. The car suddenly descended a few inches  severing Employee #1's right  big toe. Employee #1 was hospitalized and treated for his injury. During the  accident investigation it was determined that the coworker inadvertently came  into contact with the down button  which caused the dissention of the car. \",\n",
       "  'WHEN': 'September 30  2008',\n",
       "  'WHERE': 'Alimack hoist tower',\n",
       "  'EVENT': 'The car suddenly descended a few inches'},\n",
       " {'text': ' On August 24  2003  Jose Crespin Company  a stucco contractor  employed  Employee #1 and four coworkers. They were applying a stucco finish to the  exterior insulating finishing system on the Home Depot  Store Number 6555.  After completing the lumber canopy at the west end of the building  the  employees moved to the east end to finish the exterior insulating finishing  system on the spandrel panels at the garden center. While waiting for the  building surface to cool  the employees took a work break. During their break   the weather swiftly changed from clear and sunny to heavy rain and strong  winds. The employees then moved to the north side of the building at the  garden center where they hoped that the masonry piers and spandrel panels  would shelter them from the rain. The wind reached speeds in excess of 40 mph  and began collapsing the masonry piers (C.1-0.2 and C.1-0.3) where the  employees were standing. Realizing the imminent danger of the collapsing  piers  four employees fled from the area. Employee #1 became entangled in a  sheet of plastic  and was unable to break free when stub pier \"C.1-0.3\"  a  14-foot tall masonry pier  collapsed on him  crushing him. He was killed from  asphyxia.                                                                       ',\n",
       "  'WHEN': 'August 24  2003',\n",
       "  'WHERE': 'the garden center',\n",
       "  'EVENT': '14-foot tall masonry pier  collapsed on him  crushing him'},\n",
       " {'text': \" On October 24  2008  Employee #1 was working inside the freestanding carport  that was under construction  supported by vertical temporary bracing along the  outside perimeter. Employee #1's coworker was standing on the outside of the  carport with his hands resting on one of the temporary bracing. Employee #1  was operating the 20-ton bottle jack  which had an additional support on top  of the jack. Employee #1 was placing the additional support brace on top of  the bottle jack in the upward position. The support resting on the jack came  into contact with the underside wooden beams. The support in back of the jack  was removed to install trim under the area to replace the support. Employee #1  completed jacking and his coworker was about to remove the temporary vertical  wooden support  when the carport structure shifted off the temporary supports   trapping Employee #1 on the inside structure of the carport  breaking his  neck. Employee #1 died as a result of his injuries.                             \",\n",
       "  'WHEN': 'October 24  2008',\n",
       "  'WHERE': 'inside the freestanding carport',\n",
       "  'EVENT': 'trapping Employee #1 on the inside structure of the carport'},\n",
       " {'text': ' At approximately 7:15 a.m. on August 9  2007  Employee #1 and a coworker were  stripping the interior form work of a 15 ft long by 8 ft deep by 3 ft wide by  8 in. thick  type G-2 drainage inlet structure. They were doing this while the  cement slurry backfill was being poured between the excavation wall and the  north wall of the inlet structure. Two trucks  each carrying 10 cubic yards of  the slurry  had already poured in their contents. When the third truck pour  was in progress  the north wall developed vertical cracks and pushed toward  the south wall of the inlet structure  crushing Employee #1 against the south  wall. He sustained numerous bodily injuries. The coworker was able to climb  out safely.                                                                     ',\n",
       "  'WHEN': 'August 9  2007',\n",
       "  'WHERE': 'G-2 drainage inlet structure',\n",
       "  'EVENT': 'crushing Employee #1 against the south  wall'},\n",
       " {'text': ' At approximately 2:15 p.m. on June 21  2011  Employee #1 was repairing a  pipeline for a new housing development. Employee #2 laid a pipe in the trench  using an 8 ft. high trench box. The foreman noticed a separation between some  previously laid pipe and had his crew pull out the affected sections of pipe.  He went to his truck to gather some testing equipment for the pressure test  that needed to be performed on the remaining sections of piping. Employee #1  went into the trench to set up for the test  the north wall caved in. There  was no cave-in protection other than sloping the top 3 to 4 ft. portion of  excavation. Employee #1 was killed when buried. The foreman had told Employee  #1 prior to leaving the scene not to enter the trench without having the  trench box reinstalled in the trench.                                           ',\n",
       "  'WHEN': 'June 21  2011',\n",
       "  'WHERE': 'trench',\n",
       "  'EVENT': 'Employee #1 was killed when buried'},\n",
       " {'text': ' On May 21  2009  Employee #1 and #2 were building a wood frame detached  garage. After its completion  both employees decided to occupy the interior of  some trusses  when the trusses started buckling. The trusses collapsed   causing them to fall. They sustained unspecified injuries and were taken to a  local hospital for treatment. Following the medical care  they were released  the same day.                                                                   ',\n",
       "  'WHEN': 'May 21  2009',\n",
       "  'WHERE': 'a wood frame detached  garage',\n",
       "  'EVENT': 'The trusses collapsed   causing them to fall'},\n",
       " {'text': ' At approximately 1:20 p.m. on November 9  2010  Employee #1 was working for  his employer  a construction contractor  and he was assigned to work a  trenching project. Employee #1 was installing a 2-inch water line and tracer  wire in the trench  which measured approximately 6.5 feet deep and 2 feet  wide. The trench was not protected  and the spoil pile was directly adjacent  to the trench edge. Employee #1 entered the trench  and the trench wall and  spoil pile collapsed  covering Employee #1. Employee #1 was trapped for  approximately 6 to 8 minutes  and was unconscious when rescuers pulled him  from the trench. Employee #1 was transported to a local hospital and he was  admitted to intensive care. Employee #1 died from his injuries 6 days later.    ',\n",
       "  'WHEN': 'November 9  2010',\n",
       "  'WHERE': 'in the trench',\n",
       "  'EVENT': 'the trench wall and  spoil pile collapsed  covering Employee #1'},\n",
       " {'text': \" On November 6  2009  Employee #1 was in a trench  at a depth of 18 feet  when  the wall caved in on him. The employer then placed a trench box around  Employee #1 and dug him out of the trench. The local fire and ambulance  service arrived and removed Employee #1 from the trench. Employee #1's right  leg was fractured in multiple places. He was hospitalized for five days and  then relocated to a care facility  where he was recovering at the time this  report was written.                                                             \",\n",
       "  'WHEN': 'November 6  2009',\n",
       "  'WHERE': 'in a trench  at a depth of 18 feet',\n",
       "  'EVENT': 'the wall caved in on him'},\n",
       " {'text': ' Employee #1  an independent contractor at a construction site  was trying to  stand on end a wood-framed wall. The wall was too heavy for one person and  when it bumped up against a ceiling pipe while being raised  he lost control  of it. The wall fell on Employee #1  who sustained a compressed disc in his  back.                                                                           ',\n",
       "  'WHEN': '',\n",
       "  'WHERE': 'a construction site',\n",
       "  'EVENT': 'The wall fell on Employee #1'},\n",
       " {'text': ' At approximately 2:30 on July 12  2007  Employee #1 and coworkers were  installing 8 in. diameter PVC sewer pipe in an approximately 8 ft deep trench.  A coworker had just left the trench to get a connector when the entire east  side caved in and buried Employee #1. He was killed. The Morton County  Sheriff  EMS  and Fire Rescue responded to the rescue attempt  but Employee #1  was pronounced dead at the scene. The trench had been neither sloped nor  shored to prevent a trench wall cave-in.                                        ',\n",
       "  'WHEN': 'July 12  2007',\n",
       "  'WHERE': 'in an approximately 8 ft deep trench',\n",
       "  'EVENT': 'the entire east  side caved in and buried Employee #1'},\n",
       " {'text': ' At approximately 3:00 p.m. on June 17  2010  Employee #1  a plumber  and the  company general manager were laying approximately 475 ft of 4 in. PVC lateral  sewer line from a new residential dwelling to a municipal tie-in point. The  general manager was operating a Bobcat excavator  Model Number 331E   Identification Number 232711536  while Employee #1 occupied the 4 ft to 7 ft  deep trench checking the fall angle of the lateral and connecting gasket  joints with grease. Approximately 200 ft into the work  Employee #1 was  working in a 7 ft deep part of the trench near a solid wall 2.5 ft wide by 5  ft deep by 33 ft long when it sheared and collapsed. Employee #1 was killed.  Upon further investigation  it was learned that nine days prior to this event   the local electric municipal dug and backfilled an underground line from a  transformer to the residential dwelling with a trenching machine that made 4  in. to 6 in. wide cuts at a 4 ft to 5 ft depth. The trench wall ran adjacent  to the previously trenched electrical line by 2.5 ft. Due to the prior trench  work  there was inadequate sloping and backfill and an engineered tension  crack which increased the angle of internal friction and shear strength of the  wall.                                                                           ',\n",
       "  'WHEN': 'June 17  2010',\n",
       "  'WHERE': 'a new residential dwelling to a municipal tie-in point',\n",
       "  'EVENT': 'it sheared and collapsed'},\n",
       " {'text': ' At approximately 3:45 PM on April 18  2007  Employee #1 had accessed a hopper  barge to release a cable that had been used to support the barge on the  starboard side. The barge  a Flexifloat  is a modular system consisting of two  10 ft by 40 ft sections side by side with another 10 ft by 20 ft section  attached at the end. The total size was 20 ft by 50 ft. The hopper section  consisted of 1-in. plate steel. The plates were welded vertically to the deck  and the side plates were welded at an angle with steel I beams for support to  deflect material to the center. The plates were approximately 8 ft high. The  barge was used to catch construction debris from a bridge that was being  demolished. After Employee #1 released the cable  a coworker who was operating  a tug boat  put the boat at notch one in reverse to back the barge out from  under the bridge. After moving approximately 2 ft the barge listed to  starboard approximately 6 to12 inches. It then rolled back to port the same  distance  then back to even keel. It then rolled back to port and capsized  both vessels. As the vessels were rolling to the port side  Employee #1 jumped  into the water and started to swim away. The coworker  at almost the same  time  jumped from the pilot house and swam away. As the barge capsized   Employee #1 was caught in the hopper section trapping him under the barge and  he drowned.                                                                     ',\n",
       "  'WHEN': 'April 18  2007',\n",
       "  'WHERE': 'a hopper  barge',\n",
       "  'EVENT': 'he drowned'},\n",
       " {'text': ' At 12:50 p.m. on March 26  2012  Employee #1 was crossing between two 60-foot  by 80-foot barges moored in place on Nickajack Lake. Employee #1 was stepping  across a gap approximately 2 foot wide between the barges  when his fall  arrest lanyard became tangled on a mooring post. Employee #1 lost his balance  and fell from the east-most barge into the 50-degree Fahrenheit water of  Nickajack Lake. While in the water  Employee #1 became separated from his life  jacket. As fellow employees from each barge attempted to rescue him  Employee  #1 sank and drowned in 60 feet of water.                                        ',\n",
       "  'WHEN': 'March 26  2012',\n",
       "  'WHERE': 'Nickajack Lake',\n",
       "  'EVENT': 'Employee  #1 sank and drowned in 60 feet of water'},\n",
       " {'text': ' On August 18  2009  Employee #1 was inside a 140-ft long and 24-in. in  diameter pipe that ran through a tunnel underneath a highway. Employee #1 was  inside the pipe when a rain storm flooded the pipe  drowning Employee #1.       ',\n",
       "  'WHEN': 'August 18  2009',\n",
       "  'WHERE': 'tunnel underneath a highway',\n",
       "  'EVENT': 'drowning Employee #1'},\n",
       " {'text': ' At about 12:00 p.m. (noon) on September 12  2006  Employee #1  who was working  for a roofing company  went into a residential swimming pool while on lunch  break and drowned.                                                              ',\n",
       "  'WHEN': 'September 12  2006',\n",
       "  'WHERE': 'a residential swimming pool',\n",
       "  'EVENT': 'drowned'},\n",
       " {'text': ' Employee #1  a diver  became caught in a coffer dam and drowned.                ',\n",
       "  'WHEN': '',\n",
       "  'WHERE': 'a coffer dam',\n",
       "  'EVENT': 'drowned'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_5xjRKS5k-4"
   },
   "source": [
    "## 2. Vos questions\n",
    "\n",
    "Vous pouvez mettre plusieurs options de questions dans le notebook. Il est important de présenter, au minimum, les résultats pour le meilleur jeu de questions. Vous pourrez également mettre des informations à ce propos dans la section d'analyse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lEAytPstUCkx"
   },
   "source": [
    "*WHEN formulations:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "s9DaL3NB5k-4"
   },
   "outputs": [],
   "source": [
    "version1_WHEN = \"When was the employee doing staff\"\n",
    "version2_WHEN = \"What was the date of the event?\"\n",
    "version3_WHEN = \"What was the day? \"\n",
    "meuilleur_WHEN = \"What was the exact day?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l7mxpyFRUNJP"
   },
   "source": [
    "*WHEN formulations:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "HyOOB_SK5k-4"
   },
   "outputs": [],
   "source": [
    "version1_WHERE = \"where was it mostly\"\n",
    "version2_WHERE = \"where was it done?\"\n",
    "meuilleur_WHERE = \"Where was the actual place it was occuring?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SwbI7k3JUPtU"
   },
   "source": [
    "*EVENT formulations:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Shx_gS3fUUJf"
   },
   "outputs": [],
   "source": [
    "version1_EVENT = \"What was happening at the end?\"\n",
    "version2_EVENT = \"What is the most controversial thing that happened?\"\n",
    "meuilleur_EVENT = \"What is the  most astonishing thing happening?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OiwRAI207HMw"
   },
   "source": [
    "## 3. Le modèle de question-réponse extractif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "UYNo8tAt5k-5"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bLkyHgAYlcNq"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361,
     "referenced_widgets": [
      "fe9dfd2bb9a04d4a876de27a31788a48",
      "abaab5b1689448cfa46da6dc655b46e3",
      "92a382837778449c9ad2f3ef7a60ce6a",
      "df8bdb34f64d4b60867a77156edadea2",
      "c63132b8139f4c9ab46aa438bbbe31b7",
      "80305c3df04f48cc80d078a5948433a6",
      "babdf51d945f4735959bfe1aa9964a62",
      "ca3d47db30a140e8869c121ba6136cde",
      "56b0a5d7dd8644f5b27055ffab425e60",
      "515e518eefe14a10af9ba8b70ebeff81",
      "b727dae935c4496a8e8cf8b852e99239",
      "2291cad5ca834e82823128fd731dbf48",
      "a020545bbde04b66858615616859dab3",
      "2eb60b7eec314f2e8abc414155561de0",
      "7c74ef3784dd41919840bae077d09fc4",
      "a64b6664397245388ed2d8f1e542b2b8",
      "581ab8f0c40948888318373606ea9dda",
      "bf52b2b9fab6455aba21318aaeabb62a",
      "833eb72617dc4266a31523a6b9fb3b8f",
      "3628971d57734ea4a048776d2a6ce88b",
      "4e1d49fbd6fe4a22827cd2ab52c827a0",
      "95cb059b3ffd42a983ca90cbbf1c5759",
      "6340d8ccf2ba4e05ab78e3e6302dc386",
      "7f318a83e8e74d679acedec78b6ff547",
      "c5d894943d474c74a8fa6b79894d2c4e",
      "b836175b71eb41019f0afe077841ff7c",
      "6e7f11c9c3894db0a07d0134d0d5de5d",
      "90a9057c57a041c2a77eeb78ece1784f",
      "3d8ba93470f346ba82f165b421e368a9",
      "9323ae14aac94cb093ae990032558e11",
      "9e34d59d3a8745b5b6e17f4140c437ef",
      "c51ce1f72b7f4d27a31b64d54f10c3c3",
      "c11631fe6c5747589adf7a771c9417ce",
      "b3103a2d104843dea02dcb1dd556dbfb",
      "9b5dee38103e4f44bea7176c265dfe80",
      "f7cdc617504543eca85e7ad345624ae8",
      "8eb1ef85d6a84ff1ae1b9dd3b59f609d",
      "3d1a4594028c4715a055c56dd2fe952e",
      "214eefac8d844530bc685d7353b943b5",
      "4d9cb57620694cb0b19a90b4b3335e9e",
      "9f9b89917f2d45be9f933e15e605c0e5",
      "8ce7b22d86214c56a0a6cd99ad81e43a",
      "4f18df8990554ce8b6cf7a5635b5d3cd",
      "bdb934d3b08f460e84d22cf4bb551c1f",
      "8f60f3770455407c903cf34a596e6862",
      "3030f14c073a4d7dbc99dab13353d5bb",
      "6d99490a92324bcbaf65d668e7c1cdbd",
      "7d1541aab1db423e8b435418b85f48b7",
      "9fcf597ce0274d85bc804cdb730e1d56",
      "ef70a1cb16ac4152adfb89fb5270c14c",
      "e9b4adbbe5ab414e935fa5203e2a5866",
      "b26373edf4944cd69e8ae029883a955f",
      "b100b3a5cfbc45f2a73e1e41fa493991",
      "c7c9bddc8dc6405b99d8fb17cd8d14be",
      "0dd989bb54be4933a509a05f180f1721"
     ]
    },
    "id": "dqImkmfiH7JX",
    "outputId": "a1b645f6-6fba-4bfe-dde3-7fe8a19ef215",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe9dfd2bb9a04d4a876de27a31788a48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2291cad5ca834e82823128fd731dbf48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google-bert/bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6340d8ccf2ba4e05ab78e3e6302dc386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3103a2d104843dea02dcb1dd556dbfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f60f3770455407c903cf34a596e6862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = pipeline(\"question-answering\", model=\"google-bert/bert-large-uncased-whole-word-masking-finetuned-squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IWHwN_y2FFPe",
    "outputId": "1d659e42-015c-49eb-a9eb-128e678d79a2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google-bert/bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"google-bert/bert-large-uncased-whole-word-masking-finetuned-squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Pe17wp6aFFPe"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RjAf-o8j5k-5"
   },
   "source": [
    "## 4. Des fonctions utilitaires pour l'évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "SyJV4E9Q5k-5"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def remove_articles(text):\n",
    "    return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "def white_space_fix(text):\n",
    "    return ' '.join(text.split())\n",
    "\n",
    "def remove_punc(text):\n",
    "    exclude = set(string.punctuation)\n",
    "    return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "def lower(text):\n",
    "    return text.lower()\n",
    "\n",
    "def normalize_answer(s):\n",
    "    \"\"\"Mettre en minuscule et retirer la ponctuation, des déterminants and les espaces.\"\"\"\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "tISVAS_d5k-6"
   },
   "outputs": [],
   "source": [
    "def evaluate_f1(ground_truth, prediction):\n",
    "    \"\"\"Normalise les 2 textes, trouve ce qu'il y a en commun et estime précision, rappel et F1.\"\"\"\n",
    "    prediction_tokens = normalize_answer(prediction).split()\n",
    "    ground_truth_tokens = normalize_answer(ground_truth).split()\n",
    "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
    "    num_same = sum(common.values())\n",
    "    if len(ground_truth_tokens) == 0 or len(prediction_tokens) == 0:\n",
    "        return int(ground_truth_tokens == prediction_tokens)\n",
    "    if num_same == 0:\n",
    "        return 0\n",
    "    precision = 1.0 * num_same / len(prediction_tokens)\n",
    "    recall = 1.0 * num_same / len(ground_truth_tokens)\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    return f1\n",
    "\n",
    "def evaluate_exact_match(ground_truth, prediction):\n",
    "    \"\"\"Vérifie si les 2 textes sont quasi-identiques.\"\"\"\n",
    "    return (normalize_answer(prediction) == normalize_answer(ground_truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MmvlClMo5k-6"
   },
   "source": [
    "## 5. Évaluation du modèle et analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IvZwAhJaGf8V"
   },
   "source": [
    "**EVENT (juste pour connaitre effet sliding window sur EVENT):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UHMwUfg2X5fC",
    "outputId": "084c5a5b-5fea-431f-daa5-b5cbdfce6df5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Example 0: #####\n",
      "Prediction: employee # 1 was pronounced dead\n",
      "F1 score: 0.5454545454545454\n",
      "Exact Match: 0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 1: #####\n",
      "Prediction: employee # 1 suffered a serious fracture injury\n",
      "F1 score: 0\n",
      "Exact Match: 0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 2: #####\n",
      "Prediction: pronounced dead\n",
      "F1 score: 0\n",
      "Exact Match: 0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 3: #####\n",
      "Prediction: he was struck by the cement mixer that tipped over in the process of mixing cement / concrete\n",
      "F1 score: 0.5714285714285715\n",
      "Exact Match: 0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 4: #####\n",
      "Prediction: the semi - truck swerved to miss a car at employee # 1 ' s sign area and struck employee # 1\n",
      "F1 score: 0.3157894736842105\n",
      "Exact Match: 0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 5: #####\n",
      "Prediction: employee # 1 was killed\n",
      "F1 score: 0.3333333333333333\n",
      "Exact Match: 0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 6: #####\n",
      "Prediction: the employee moved and his left foot was struck by and run over by a loader\n",
      "F1 score: 0.88\n",
      "Exact Match: 0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 7: #####\n",
      "Prediction: employee # 1 fell off the dock lock and was pinned between the loading dock and trailer. he suffered a fractured pelvis a ruptured bladder and leg vein damage\n",
      "F1 score: 0.7368421052631579\n",
      "Exact Match: 0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 8: #####\n",
      "Prediction: he was walking west across the on - ramp to remove another barrel and was struck by the dump truck\n",
      "F1 score: 0.38095238095238093\n",
      "Exact Match: 0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 9: #####\n",
      "Prediction: the car suddenly descended a few inches severing employee # 1 ' s right big toe\n",
      "F1 score: 0.5882352941176471\n",
      "Exact Match: 0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 10: #####\n",
      "Prediction: a 14 - foot tall masonry pier collapsed on him crushing him\n",
      "F1 score: 0.8421052631578948\n",
      "Exact Match: 0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 11: #####\n",
      "Prediction: breaking his neck\n",
      "F1 score: 0\n",
      "Exact Match: 0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 12: #####\n",
      "Prediction: the north wall developed vertical cracks and pushed toward the south wall of the inlet structure crushing employee # 1 against the south wall\n",
      "F1 score: 0.4799999999999999\n",
      "Exact Match: 0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 13: #####\n",
      "Prediction: the north wall caved in\n",
      "F1 score: 0\n",
      "Exact Match: 0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 14: #####\n",
      "Prediction: the trusses collapsed causing them to fall\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 15: #####\n",
      "Prediction: the trench wall and spoil pile collapsed\n",
      "F1 score: 0.8\n",
      "Exact Match: 0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 16: #####\n",
      "Prediction: employee # 1 ' s right leg was fractured in multiple places\n",
      "F1 score: 0.13333333333333333\n",
      "Exact Match: 0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 17: #####\n",
      "Prediction: the wall fell on employee # 1 who sustained a compressed disc in his back\n",
      "F1 score: 0.5882352941176471\n",
      "Exact Match: 0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 18: #####\n",
      "Prediction: the entire east side caved in and buried employee # 1\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 19: #####\n",
      "Prediction: it sheared and collapsed\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 20: #####\n",
      "Prediction: capsized both vessels\n",
      "F1 score: 0\n",
      "Exact Match: 0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 21: #####\n",
      "Prediction: sank and drowned\n",
      "F1 score: 0.4615384615384615\n",
      "Exact Match: 0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 22: #####\n",
      "Prediction: a rain storm flooded the pipe drowning employee # 1\n",
      "F1 score: 0.6\n",
      "Exact Match: 0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 23: #####\n",
      "Prediction: drowned\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 24: #####\n",
      "Prediction: a diver became caught in a coffer dam and drowned\n",
      "F1 score: 0.2222222222222222\n",
      "Exact Match: 0 \n",
      "\n",
      "#########\n",
      "\n",
      "Number correct EVENT: 2\n",
      "8.00% correct answers\n",
      "0.50 Average F1 Score\n",
      "16.00% Average Exact Match Score\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Parameters\n",
    "window_size = 512  # Max tokens per window\n",
    "stride = 32  # Overlap size\n",
    "# windSz 512 , stride 64 , f1 score 0.49 , 20%\n",
    "# Split text into overlapping windows\n",
    "def sliding_windows(text, window_size, stride):\n",
    "    input_ids = tokenizer.encode(text, add_special_tokens=False)\n",
    "    windows = []\n",
    "    for i in range(0, len(input_ids), stride):\n",
    "        window = input_ids[i:i + window_size]\n",
    "        windows.append(window)\n",
    "    return windows\n",
    "\n",
    "# Initialize scores\n",
    "s = 0\n",
    "f = 0\n",
    "exM = 0\n",
    "\n",
    "for i in range(len(data)):\n",
    "    text_data = data[i]['text']\n",
    "    ground_truth = data[i][\"EVENT\"]\n",
    "    question, text = \"What is the  most astonishing thing happening?\", text_data\n",
    "\n",
    "    windows = sliding_windows(text_data, window_size, stride)\n",
    "    answers = []\n",
    "\n",
    "    # Get answers from each window\n",
    "    for window in windows:\n",
    "        tokens = tokenizer.convert_ids_to_tokens(window, skip_special_tokens=True)\n",
    "        window_text = tokenizer.convert_tokens_to_string(tokens)\n",
    "\n",
    "        inputs = tokenizer.encode_plus(question, window_text, return_tensors=\"pt\", truncation=True, max_length=window_size)\n",
    "        input_ids = inputs[\"input_ids\"]\n",
    "        attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        start_scores = outputs.start_logits\n",
    "        end_scores = outputs.end_logits\n",
    "        all_tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "\n",
    "        # Get the best answer within this window\n",
    "        answer_start = torch.argmax(start_scores)\n",
    "        answer_end = torch.argmax(end_scores) + 1\n",
    "\n",
    "        if answer_start < answer_end and answer_end <= len(all_tokens):\n",
    "            answer = tokenizer.convert_tokens_to_string(all_tokens[answer_start:answer_end])\n",
    "            score = start_scores[0][answer_start] + end_scores[0][answer_end - 1]\n",
    "            answers.append((answer, score.item()))\n",
    "\n",
    "    # Select the best answer based on score\n",
    "    prediction = max(answers, key=lambda x: x[1])[0] if answers else \"\"\n",
    "\n",
    "    # Evaluate performance\n",
    "    f1_score = evaluate_f1(ground_truth, prediction)\n",
    "    f += f1_score\n",
    "    exact_match = evaluate_exact_match(ground_truth, prediction)\n",
    "    exM += int(exact_match)\n",
    "\n",
    "    print(f\"##### Example {i}: #####\")\n",
    "    print(\"Prediction:\", prediction)\n",
    "    print(\"F1 score:\", f1_score)\n",
    "    print(\"Exact Match:\", int(exact_match), \"\\n\")\n",
    "    print(\"#########\\n\")\n",
    "\n",
    "    if prediction.lower() == ground_truth.lower():\n",
    "        s += 1\n",
    "\n",
    "# Final Metrics\n",
    "percentage = (s / len(data)) * 100\n",
    "print(f\"Number correct EVENT: {s}\")\n",
    "print(f\"{percentage:.2f}% correct answers\")\n",
    "print(f\"{f / len(data):.2f} Average F1 Score\")\n",
    "print(f\"{(exM / len(data)) * 100:.2f}% Average Exact Match Score\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zezdk2NTG9Rn"
   },
   "source": [
    "**WHERE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bdd3X2ItLzUI",
    "outputId": "52516e8d-d614-458a-fcc9-551879182dfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### example 0: #####\n",
      "a railroad bridge over\n",
      "f1 score:  0.6666666666666666\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 1: #####\n",
      "menlo park california\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 2: #####\n",
      "bathroom facility\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 3: #####\n",
      "cement mixer. he was struck by the cement mixer that tipped over in the process of mixing cement / concrete\n",
      "f1 score:  0.10526315789473684\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 4: #####\n",
      "iowa\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 5: #####\n",
      "the emergency shoulder of an interstate highway\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 6: #####\n",
      "inside a tunnel pipeline\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 7: #####\n",
      "birds eye foods to service the dock lock on bay number 3\n",
      "f1 score:  0.42857142857142855\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 8: #####\n",
      "interstate 15 ( i - 15 ) and approximately 14100 south\n",
      "f1 score:  0.7999999999999999\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 9: #####\n",
      "alimack hoist tower\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 10: #####\n",
      "home depot store number 6555\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 11: #####\n",
      "inside the freestanding carport\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 12: #####\n",
      "interior form work\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 13: #####\n",
      "trench\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 14: #####\n",
      "interior of some trusses\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 15: #####\n",
      "trenching project. employee # 1 was installing a 2 - inch water line and tracer wire in the trench\n",
      "f1 score:  0.23529411764705882\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 16: #####\n",
      "trench at a depth of 18 feet\n",
      "f1 score:  0.923076923076923\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 17: #####\n",
      "wood - framed wall. the wall was too heavy for one person and when it bumped up against a ceiling pipe\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 18: #####\n",
      "east side\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 19: #####\n",
      "a new residential dwelling\n",
      "f1 score:  0.6\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 20: #####\n",
      "starboard side\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 21: #####\n",
      "nickajack lake\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 22: #####\n",
      "tunnel underneath a highway\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 23: #####\n",
      "residential swimming pool\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 24: #####\n",
      "coffer dam\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "0.5903548917542725  moyenne de F1 - Score\n",
      "44.0 % moyenne de Exact Match - Score\n"
     ]
    }
   ],
   "source": [
    "\n",
    "f=0\n",
    "exM=0\n",
    "\n",
    "for i in range(len(data)):\n",
    "  text_data = data[i]['text']\n",
    "  ground_truth = data[i][\"WHERE\"]\n",
    "  question,text = \"where was it mostly?\",text_data\n",
    "\n",
    "  chunk_size = 512\n",
    "  text_debut=text[:chunk_size]\n",
    "  head = text[:chunk_size//2]\n",
    "  tail = text[-chunk_size//2:]\n",
    "\n",
    "  text_final = text[-chunk_size:]\n",
    "  head_1 = text[:chunk_size//3]\n",
    "  head_2 = text[chunk_size//6:chunk_size*2//3]\n",
    "  head_3 = text[chunk_size*5//6:chunk_size*3//3]\n",
    "\n",
    "  #combined head and tail at the begining and in the middle\n",
    "  head_debut = text[:chunk_size//2]\n",
    "  tail_debut = text[chunk_size//4:chunk_size//2]\n",
    "  head_debut_2 = text[-chunk_size//2:]\n",
    "  tail_debut_2 = text[chunk_size*3//4:chunk_size]\n",
    "  inputs = tokenizer(question, head , return_tensors=\"pt\")\n",
    "  with torch.no_grad():\n",
    "      outputs = model(**inputs)\n",
    "\n",
    "  answer_start_index = outputs.start_logits.argmax()\n",
    "  answer_end_index = outputs.end_logits.argmax()\n",
    "\n",
    "  predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "  prediction = tokenizer.decode(predict_answer_tokens, skip_special_tokens=True)\n",
    "\n",
    "  When_part = data[i][\"WHERE\"]\n",
    "  f1_score = evaluate_f1(ground_truth, prediction)\n",
    "  exact_match = evaluate_exact_match(ground_truth, prediction)\n",
    "\n",
    "  f+=f1_score\n",
    "  exM+=int(exact_match)\n",
    "  print(\"##### example {}: #####\".format(i))\n",
    "  print(prediction)\n",
    "  print(\"f1 score: \",f1_score)\n",
    "  print(\"exact_match: \",int(exact_match),\"\\n\")\n",
    "  print(\"#########\\n\")\n",
    "\n",
    "print(\"{}  moyenne de F1 - Score\".format(f/25))\n",
    "print(\"{} % moyenne de Exact Match - Score\".format((exM/25)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kCd4Pt9IMchr",
    "outputId": "bf19be5f-b8b8-429e-c6ca-f3fbf9f3686f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### example 0: #####\n",
      "railroad bridge\n",
      "f1 score:  0.8\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 1: #####\n",
      "menlo park california\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 2: #####\n",
      "st. james hospital in chicago heights\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 3: #####\n",
      "mixing cement / concrete\n",
      "f1 score:  0.4\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 4: #####\n",
      "iowa erosion control inc.\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 5: #####\n",
      "in the emergency shoulder of an interstate highway\n",
      "f1 score:  0.9090909090909091\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 6: #####\n",
      "inside a tunnel pipeline\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 7: #####\n",
      "birds eye foods\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 8: #####\n",
      "on interstate 15 ( i - 15 ) and approximately 14100 south\n",
      "f1 score:  0.75\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 9: #####\n",
      "alimack hoist tower\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 10: #####\n",
      "home depot store number 6555\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 11: #####\n",
      "inside the freestanding carport\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 12: #####\n",
      "while the cement slurry bac and pushed toward the south wall of the inlet structure\n",
      "f1 score:  0.25\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 13: #####\n",
      "repairing a pipeline for a new housing development\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 14: #####\n",
      "building a wood frame detached garage\n",
      "f1 score:  0.888888888888889\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 15: #####\n",
      "trenching project. employee # 1 was installing a 2 - inch water line and tracer wire in the trench\n",
      "f1 score:  0.23529411764705882\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 16: #####\n",
      "\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 17: #####\n",
      "a construction site\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 18: #####\n",
      "an approximately 8 ft deep trench\n",
      "f1 score:  0.9090909090909091\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 19: #####\n",
      "from a new residential dwelling to a municipal tie - in point\n",
      "f1 score:  0.75\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 20: #####\n",
      "a hopper barge\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 21: #####\n",
      "nickajack lake\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 22: #####\n",
      "tunnel underneath a highway\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 23: #####\n",
      "residential swimming pool\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 24: #####\n",
      "a coffer dam\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "0.6756945929887107  moyenne de F1 - Score\n",
      "44.0 % moyenne de Exact Match - Score\n"
     ]
    }
   ],
   "source": [
    "\n",
    "f=0\n",
    "exM=0\n",
    "#\"where was it done?\" 67% 52% text_debut   (en bas cellule)\n",
    "\n",
    "#\"where was it?\" head + tail 63.66% 36%\n",
    "#\"where was it mostly?\" 59% 44%   head (512// 2)\n",
    "# \"where was it mostly?\" 53.91% 48% head(first only)\n",
    "# \"where was it occuring?\" 58.94 44% head + tail\n",
    "# \"where was it occuring?\" 65.34 24% head_debut + tail_debut\n",
    "#\"Where was the actual place it was occuring?\" 68.26%  52%   (head_debut + tail_debut)  | 67.59% 52% (head) |  73.1%  64%(first tokens 512  (text_debut))  | 50% (text_final) | 74.31%  64% (text_debut + head_3)\n",
    "#\"Where was the actual place it was taken place in?\"  70% (512 first token)\n",
    "for i in range(len(data)):\n",
    "  text_data = data[i]['text']\n",
    "  ground_truth = data[i][\"WHERE\"]\n",
    "  question,text = \"where was it done?\",text_data\n",
    "\n",
    "  chunk_size = 512\n",
    "  text_debut=text[:chunk_size]\n",
    "  head = text[:chunk_size//2]\n",
    "  tail = text[-chunk_size//2:]\n",
    "\n",
    "  text_final = text[-chunk_size:]\n",
    "  head_1 = text[:chunk_size//3]\n",
    "  head_2 = text[chunk_size//6:chunk_size*2//3]\n",
    "  head_3 = text[chunk_size*5//6:chunk_size*3//3]\n",
    "\n",
    "  #combined head and tail at the begining and in the middle\n",
    "  head_debut = text[:chunk_size//2]\n",
    "  tail_debut = text[chunk_size//4:chunk_size//2]\n",
    "  head_debut_2 = text[-chunk_size//2:]\n",
    "  tail_debut_2 = text[chunk_size*3//4:chunk_size]\n",
    "  inputs = tokenizer(question, head + tail , return_tensors=\"pt\")\n",
    "  with torch.no_grad():\n",
    "      outputs = model(**inputs)\n",
    "\n",
    "  answer_start_index = outputs.start_logits.argmax()\n",
    "  answer_end_index = outputs.end_logits.argmax()\n",
    "\n",
    "  predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "  prediction = tokenizer.decode(predict_answer_tokens, skip_special_tokens=True)\n",
    "\n",
    "  When_part = data[i][\"WHERE\"]\n",
    "  f1_score = evaluate_f1(ground_truth, prediction)\n",
    "  exact_match = evaluate_exact_match(ground_truth, prediction)\n",
    "\n",
    "  f+=f1_score\n",
    "  exM+=int(exact_match)\n",
    "  print(\"##### example {}: #####\".format(i))\n",
    "  print(prediction)\n",
    "  print(\"f1 score: \",f1_score)\n",
    "  print(\"exact_match: \",int(exact_match),\"\\n\")\n",
    "  print(\"#########\\n\")\n",
    "\n",
    "print(\"{}  moyenne de F1 - Score\".format(f/25))\n",
    "print(\"{} % moyenne de Exact Match - Score\".format((exM/25)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sR3rwZeRM0RB",
    "outputId": "eebc41d1-b246-4c57-e58c-40f4329b12a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### example 0: #####\n",
      "railroad bridge overpass\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 1: #####\n",
      "menlo park california\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 2: #####\n",
      "st. james hospital\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 3: #####\n",
      "mixing cement / concrete\n",
      "f1 score:  0.4\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 4: #####\n",
      "iowa erosion control inc. was turning a vertical sign from stop to slow based upon the location of a pilot car running between the worker ' s location and a second coworker \" flagger \" located approximately one mile away\n",
      "f1 score:  0.17142857142857143\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 5: #####\n",
      "the emergency shoulder of an interstate highway\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 6: #####\n",
      "inside a tunnel pipeline\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 7: #####\n",
      "birds eye foods\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 8: #####\n",
      "interstate 15 ( i - 15 ) and approximately 14100 south\n",
      "f1 score:  0.7999999999999999\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 9: #####\n",
      "alimack hoist tower\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 10: #####\n",
      "home depot store number 6555. after completing the lumber canopy at the west end of the building the employees moved to the east end to finish the exterior insulating finishing system on the spandrel panels at the garden center\n",
      "f1 score:  0.12121212121212122\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 11: #####\n",
      "inside the freestanding carport\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 12: #####\n",
      "between the excavation wall and the north wall of the inlet structure\n",
      "f1 score:  0.30769230769230765\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 13: #####\n",
      "repairing a pipeline for a new housing development. employee # 2 laid a pipe in the trench\n",
      "f1 score:  0.15384615384615385\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 14: #####\n",
      "\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 15: #####\n",
      "in the trench\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 16: #####\n",
      "\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 17: #####\n",
      "a construction site\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 18: #####\n",
      "an approximately 8 ft deep trench\n",
      "f1 score:  0.9090909090909091\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 19: #####\n",
      "a new residential dwelling to a municipal tie - in point\n",
      "f1 score:  0.7999999999999999\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 20: #####\n",
      "a hopper barge\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 21: #####\n",
      "nickajack lake\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 22: #####\n",
      "tunnel underneath a highway\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 23: #####\n",
      "residential swimming pool\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 24: #####\n",
      "a coffer dam\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "0.7065308025308025  moyenne de F1 - Score\n",
      "56.00000000000001 % moyenne de Exact Match - Score\n"
     ]
    }
   ],
   "source": [
    "\n",
    "f=0\n",
    "exM=0\n",
    "#\"where was it done?\" 67% 52% text_debut   (en bas cellule)\n",
    "\n",
    "#\"where was it?\" head + tail 63.66% 36%\n",
    "#\"where was it mostly?\" 59% 44%   head (512// 2)\n",
    "# \"where was it mostly?\" 53.91% 48% head(first only)\n",
    "# \"where was it occuring?\" 58.94 44% head + tail\n",
    "# \"where was it occuring?\" 65.34 24% head_debut + tail_debut\n",
    "#\"Where was the actual place it was occuring?\" 68.26%  52%   (head_debut + tail_debut)  | 67.59% 52% (head) |  73.1%  64%(first tokens 512  (text_debut))  | 50% (text_final) | 74.31%  64% (text_debut + head_3)\n",
    "#\"Where was the actual place it was taken place in?\"  70% (512 first token)\n",
    "for i in range(len(data)):\n",
    "  text_data = data[i]['text']\n",
    "  ground_truth = data[i][\"WHERE\"]\n",
    "  question,text = \"where was it done?\",text_data\n",
    "\n",
    "  chunk_size = 512\n",
    "  text_debut=text[:chunk_size]\n",
    "  head = text[:chunk_size//2]\n",
    "  tail = text[-chunk_size//2:]\n",
    "\n",
    "  text_final = text[-chunk_size:]\n",
    "  head_1 = text[:chunk_size//3]\n",
    "  head_2 = text[chunk_size//6:chunk_size*2//3]\n",
    "  head_3 = text[chunk_size*5//6:chunk_size*3//3]\n",
    "\n",
    "  #combined head and tail at the begining and in the middle\n",
    "  head_debut = text[:chunk_size//2]\n",
    "  tail_debut = text[chunk_size//4:chunk_size//2]\n",
    "  head_debut_2 = text[-chunk_size//2:]\n",
    "  tail_debut_2 = text[chunk_size*3//4:chunk_size]\n",
    "  inputs = tokenizer(question, text_debut , return_tensors=\"pt\")\n",
    "  with torch.no_grad():\n",
    "      outputs = model(**inputs)\n",
    "\n",
    "  answer_start_index = outputs.start_logits.argmax()\n",
    "  answer_end_index = outputs.end_logits.argmax()\n",
    "\n",
    "  predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "  prediction = tokenizer.decode(predict_answer_tokens, skip_special_tokens=True)\n",
    "\n",
    "  When_part = data[i][\"WHERE\"]\n",
    "  f1_score = evaluate_f1(ground_truth, prediction)\n",
    "  exact_match = evaluate_exact_match(ground_truth, prediction)\n",
    "\n",
    "  f+=f1_score\n",
    "  exM+=int(exact_match)\n",
    "  print(\"##### example {}: #####\".format(i))\n",
    "  print(prediction)\n",
    "  print(\"f1 score: \",f1_score)\n",
    "  print(\"exact_match: \",int(exact_match),\"\\n\")\n",
    "  print(\"#########\\n\")\n",
    "\n",
    "print(\"{}  moyenne de F1 - Score\".format(f/25))\n",
    "print(\"{} % moyenne de Exact Match - Score\".format((exM/25)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BtXg85WrNK4D",
    "outputId": "506ed382-9328-4ff5-e003-a4a416abc845"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### example 0: #####\n",
      "railroad bridge overpass\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 1: #####\n",
      "menlo park california\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 2: #####\n",
      "a bathroom facility\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 3: #####\n",
      "mixing cement / concrete\n",
      "f1 score:  0.4\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 4: #####\n",
      "one mile away\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 5: #####\n",
      "the emergency shoulder of an interstate highway\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 6: #####\n",
      "inside a tunnel pipeline\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 7: #####\n",
      "birds eye foods\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 8: #####\n",
      "utah county line to 12300 south in salt lake county\n",
      "f1 score:  0.11764705882352941\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 9: #####\n",
      "alimack hoist tower\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 10: #####\n",
      "home depot store number 6555\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 11: #####\n",
      "inside the freestanding carport\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 12: #####\n",
      "between the excavation wall and the north wall of the inlet structure\n",
      "f1 score:  0.30769230769230765\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 13: #####\n",
      "trench\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 14: #####\n",
      "\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 15: #####\n",
      "trenching project. employee # 1 was installing a 2 - inch water line and tracer wire in the trench\n",
      "f1 score:  0.23529411764705882\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 16: #####\n",
      "a trench at a depth of 18 feet\n",
      "f1 score:  0.923076923076923\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 17: #####\n",
      "a construction site\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 18: #####\n",
      "\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 19: #####\n",
      "a new residential dwelling\n",
      "f1 score:  0.6\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 20: #####\n",
      "a hopper barge\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 21: #####\n",
      "nickajack lake\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 22: #####\n",
      "a tunnel underneath a highway\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 23: #####\n",
      "residential swimming pool\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 24: #####\n",
      "a coffer dam\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "0.7433484162895928  moyenne de F1 - Score\n",
      "64.0 % moyenne de Exact Match - Score\n"
     ]
    }
   ],
   "source": [
    "\n",
    "f=0\n",
    "exM=0\n",
    "#\"where was it done?\" 67% 52% text_debut   (en bas cellule)\n",
    "\n",
    "#\"where was it?\" head + tail 63.66% 36%\n",
    "#\"where was it mostly?\" 59% 44%   head (512// 2)\n",
    "# \"where was it mostly?\" 53.91% 48% head(first only)\n",
    "# \"where was it occuring?\" 58.94 44% head + tail\n",
    "# \"where was it occuring?\" 65.34 24% head_debut + tail_debut\n",
    "#\"Where was the actual place it was occuring?\" 68.26%  52%   (head_debut + tail_debut)  | 67.59% 52% (head) |  73.1%  64%(first tokens 512  (text_debut))  | 50% (text_final) | 74.31%  64% (text_debut + head_3)\n",
    "#\"Where was the actual place it was taken place in?\"  70% (512 first token)\n",
    "for i in range(len(data)):\n",
    "  text_data = data[i]['text']\n",
    "  ground_truth = data[i][\"WHERE\"]\n",
    "  question,text = \"Where was the actual place it was occuring?\",text_data\n",
    "\n",
    "  chunk_size = 512\n",
    "  text_debut=text[:chunk_size]\n",
    "  head = text[:chunk_size//2]\n",
    "  tail = text[-chunk_size//2:]\n",
    "\n",
    "  text_final = text[-chunk_size:]\n",
    "  head_1 = text[:chunk_size//3]\n",
    "  head_2 = text[chunk_size//6:chunk_size*2//3]\n",
    "  head_3 = text[chunk_size*5//6:chunk_size*3//3]\n",
    "\n",
    "  #combined head and tail at the begining and in the middle\n",
    "  head_debut = text[:chunk_size//2]\n",
    "  tail_debut = text[chunk_size//4:chunk_size//2]\n",
    "  head_debut_2 = text[-chunk_size//2:]\n",
    "  tail_debut_2 = text[chunk_size*3//4:chunk_size]\n",
    "  inputs = tokenizer(question, text_debut + head_3 , return_tensors=\"pt\")\n",
    "  with torch.no_grad():\n",
    "      outputs = model(**inputs)\n",
    "\n",
    "  answer_start_index = outputs.start_logits.argmax()\n",
    "  answer_end_index = outputs.end_logits.argmax()\n",
    "\n",
    "  predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "  prediction = tokenizer.decode(predict_answer_tokens, skip_special_tokens=True)\n",
    "\n",
    "  When_part = data[i][\"WHERE\"]\n",
    "  f1_score = evaluate_f1(ground_truth, prediction)\n",
    "  exact_match = evaluate_exact_match(ground_truth, prediction)\n",
    "\n",
    "  f+=f1_score\n",
    "  exM+=int(exact_match)\n",
    "  print(\"##### example {}: #####\".format(i))\n",
    "  print(prediction)\n",
    "  print(\"f1 score: \",f1_score)\n",
    "  print(\"exact_match: \",int(exact_match),\"\\n\")\n",
    "  print(\"#########\\n\")\n",
    "\n",
    "print(\"{}  moyenne de F1 - Score\".format(f/25))\n",
    "print(\"{} % moyenne de Exact Match - Score\".format((exM/25)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vs_OdMO8QHX_",
    "outputId": "53d7d4c7-b55e-4209-e681-3af5c702fdee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### example 0: #####\n",
      "railroad bridge overpass\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 1: #####\n",
      "menlo park california\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 2: #####\n",
      "a bathroom facility\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 3: #####\n",
      "mixing cement / concrete\n",
      "f1 score:  0.4\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 4: #####\n",
      "one mile away\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 5: #####\n",
      "the emergency shoulder of an interstate highway\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 6: #####\n",
      "inside a tunnel pipeline\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 7: #####\n",
      "birds eye foods\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 8: #####\n",
      "utah county line to 12300 south in salt lake county\n",
      "f1 score:  0.11764705882352941\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 9: #####\n",
      "alimack hoist tower\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 10: #####\n",
      "home depot store number 6555\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 11: #####\n",
      "inside the freestanding carport\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 12: #####\n",
      "\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 13: #####\n",
      "trench\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 14: #####\n",
      "\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 15: #####\n",
      "trenching project. employee # 1 was installing a 2 - inch water line and tracer wire in the trench\n",
      "f1 score:  0.23529411764705882\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 16: #####\n",
      "a trench at a depth of 18 feet\n",
      "f1 score:  0.923076923076923\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 17: #####\n",
      "a construction site\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 18: #####\n",
      "\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 19: #####\n",
      "a new residential dwelling\n",
      "f1 score:  0.6\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 20: #####\n",
      "a hopper barge\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 21: #####\n",
      "nickajack lake\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 22: #####\n",
      "a tunnel underneath a highway\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 23: #####\n",
      "residential swimming pool\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 24: #####\n",
      "a coffer dam\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "0.7310407239819005  moyenne de F1 - Score\n",
      "64.0 % moyenne de Exact Match - Score\n"
     ]
    }
   ],
   "source": [
    "\n",
    "f=0\n",
    "exM=0\n",
    "#\"where was it done?\" 67% 52% text_debut   (en bas cellule)\n",
    "\n",
    "#\"where was it?\" head + tail 63.66% 36%\n",
    "#\"where was it mostly?\" 59% 44%   head (512// 2)\n",
    "# \"where was it mostly?\" 53.91% 48% head(first only)\n",
    "# \"where was it occuring?\" 58.94 44% head + tail\n",
    "# \"where was it occuring?\" 65.34 24% head_debut + tail_debut\n",
    "#\"Where was the actual place it was occuring?\" 68.26%  52%   (head_debut + tail_debut)  | 67.59% 52% (head) |  73.1%  64%(first tokens 512  (text_debut))  | 50% (text_final) | 74.31%  64% (text_debut + head_3)\n",
    "#\"Where was the actual place it was taken place in?\"  70% (512 first token)\n",
    "for i in range(len(data)):\n",
    "  text_data = data[i]['text']\n",
    "  ground_truth = data[i][\"WHERE\"]\n",
    "  question,text = \"Where was the actual place it was occuring?\",text_data\n",
    "\n",
    "  chunk_size = 512\n",
    "  text_debut=text[:chunk_size]\n",
    "  head = text[:chunk_size//2]\n",
    "  tail = text[-chunk_size//2:]\n",
    "\n",
    "  text_final = text[-chunk_size:]\n",
    "  head_1 = text[:chunk_size//3]\n",
    "  head_2 = text[chunk_size//6:chunk_size*2//3]\n",
    "  head_3 = text[chunk_size*5//6:chunk_size*3//3]\n",
    "\n",
    "  #combined head and tail at the begining and in the middle\n",
    "  head_debut = text[:chunk_size//2]\n",
    "  tail_debut = text[chunk_size//4:chunk_size//2]\n",
    "  head_debut_2 = text[-chunk_size//2:]\n",
    "  tail_debut_2 = text[chunk_size*3//4:chunk_size]\n",
    "  inputs = tokenizer(question, text_debut , return_tensors=\"pt\")\n",
    "  with torch.no_grad():\n",
    "      outputs = model(**inputs)\n",
    "\n",
    "  answer_start_index = outputs.start_logits.argmax()\n",
    "  answer_end_index = outputs.end_logits.argmax()\n",
    "\n",
    "  predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "  prediction = tokenizer.decode(predict_answer_tokens, skip_special_tokens=True)\n",
    "\n",
    "  When_part = data[i][\"WHERE\"]\n",
    "  f1_score = evaluate_f1(ground_truth, prediction)\n",
    "  exact_match = evaluate_exact_match(ground_truth, prediction)\n",
    "\n",
    "  f+=f1_score\n",
    "  exM+=int(exact_match)\n",
    "  print(\"##### example {}: #####\".format(i))\n",
    "  print(prediction)\n",
    "  print(\"f1 score: \",f1_score)\n",
    "  print(\"exact_match: \",int(exact_match),\"\\n\")\n",
    "  print(\"#########\\n\")\n",
    "\n",
    "print(\"{}  moyenne de F1 - Score\".format(f/25))\n",
    "print(\"{} % moyenne de Exact Match - Score\".format((exM/25)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aik8oxRtNlH"
   },
   "source": [
    "**EVENT**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Te3pyWw2vvMq"
   },
   "source": [
    "2ème forrmulation (head + tail + head-4 + tail_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0FwJNFRbv3ja",
    "outputId": "2b0d90ed-b09a-4eea-8675-12abd453486e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### example 0: #####\n",
      "employee # 1 was struck and thrown some 100 ft from where he was originally standing. the vehicle was moving approximately 45 mph per hour. as he was transferred to a hospital by emergency personnel employee # 1 was treated for severe trauma lacerations fractures and contusions\n",
      "f1 score:  0.24489795918367346\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 1: #####\n",
      "employee # 1 suffered a serious fracture injury to his left leg\n",
      "f1 score:  0.16\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 2: #####\n",
      "employee # 1 had a seizure\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 3: #####\n",
      "he was struck by the cement mixer that tipped over in the process of mixing cement / concrete\n",
      "f1 score:  0.5714285714285715\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 4: #####\n",
      "employee # 1 was killed\n",
      "f1 score:  0.5714285714285715\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 5: #####\n",
      "employee # 1 was killed\n",
      "f1 score:  0.3333333333333333\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 6: #####\n",
      "the employee moved and his left foot was struck by and run over by a loader\n",
      "f1 score:  0.88\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 7: #####\n",
      "he parked his service truck in front of bay number 3. a tractor - trailer unit wdock lock and was pinned between the loading dock and trailer. he suffered a fractured pelvis a ruptured bladder and leg vein damage\n",
      "f1 score:  0.37499999999999994\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 8: #####\n",
      "employee # 1 was killed\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 9: #####\n",
      "the coworker inadvertently came into contact with the down button which caused the dissention of the car\n",
      "f1 score:  0.1111111111111111\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 10: #####\n",
      "he was killed from asphyxia\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 11: #####\n",
      "breaking his neck\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 12: #####\n",
      "they were doing this while the cement slurry bac and pushed toward the south wall of the inlet structure crushing employee # 1 against the south wall\n",
      "f1 score:  0.42857142857142855\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 13: #####\n",
      "employee # 1 was killed when buried\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 14: #####\n",
      "the trusses collapsed causing them to fall\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 15: #####\n",
      "employee # 1 died from his injuries 6 days later.\n",
      "f1 score:  0.2222222222222222\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 16: #####\n",
      "the wall caved in on him\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 17: #####\n",
      "\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 18: #####\n",
      "the entire east side caved in and buried ed\n",
      "f1 score:  0.823529411764706\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 19: #####\n",
      "prior trench work there was inadequate sloping and backfill and an engineered tension crack\n",
      "f1 score:  0.11764705882352941\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 20: #####\n",
      "he drowned\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 21: #####\n",
      "drowned\n",
      "f1 score:  0.18181818181818182\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 22: #####\n",
      "a rain storm flooded the pipe drowning employee # 1\n",
      "f1 score:  0.6\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 23: #####\n",
      "drowned\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 24: #####\n",
      "employee # 1 a diver became caught in a coffer dam and drowned\n",
      "f1 score:  0.18181818181818182\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "0.4721122412601404  moyenne de F1 - Score\n",
      "24.0 % moyenne de Exact Match - Score\n"
     ]
    }
   ],
   "source": [
    "s = 0\n",
    "f=0\n",
    "exM=0\n",
    "#\"What was happening after what occured in the place where was it done?\"\n",
    "#\"What was happening at the end?\" 38%\n",
    "#\"What the most thing that was happening and marking the story  at the end?\"  31%\n",
    "# \"What the most thing that was happening and marking the story?\" 31%\n",
    "#\"What the most thing that was happening  in the story?\" 31%\n",
    "#\"What the most thing that was happening?\" 43.83 (the most > 43.27)\n",
    "# \"What is the most controversial thing that happened?\" (46%)\n",
    "# \"What is the worst and risky thing happening?\" 47.88%\n",
    "#\"What is the  most astonishing thing happening?\"  head_only  (41%  16%) |  (head + tail) 50.61%   24%  | 54.61%  28% (head + tail + head_4 + tail_4)\n",
    "for i in range(len(data)):\n",
    "  text_data = data[i]['text']\n",
    "  ground_truth = data[i][\"EVENT\"]\n",
    "  question,text = \"What is the most controversial thing that happened?\",text_data\n",
    "\n",
    "  chunk_size = 512\n",
    "  head_only = text[:chunk_size]\n",
    "  head = text[:chunk_size//2]\n",
    "  tail = text[-chunk_size//2:]\n",
    "\n",
    "  head_2 = text[chunk_size:chunk_size+ 513]\n",
    "  tail_2 = text[chunk_size + 512: chunk_size + 1024]\n",
    "\n",
    "  head_3 = text[chunk_size + 1024: chunk_size + 1536]\n",
    "  tail_3 = text[chunk_size + 1536: chunk_size + 2048]\n",
    "\n",
    "  head_4 = text[chunk_size + 2048: chunk_size + 256]\n",
    "  tail_4 = text[chunk_size + 2560: chunk_size + 3071]\n",
    "\n",
    "  tail_only = text[-chunk_size:]\n",
    "  inputs = tokenizer(question, head + tail + head_4 + tail_4 , return_tensors=\"pt\")\n",
    "  with torch.no_grad():\n",
    "      outputs = model(**inputs)\n",
    "\n",
    "  answer_start_index = outputs.start_logits.argmax()\n",
    "  answer_end_index = outputs.end_logits.argmax()\n",
    "\n",
    "  predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "  prediction = tokenizer.decode(predict_answer_tokens, skip_special_tokens=True)\n",
    "\n",
    "  When_part = data[i][\"EVENT\"]\n",
    "  f1_score = evaluate_f1(ground_truth, prediction)\n",
    "  f+=f1_score\n",
    "  exact_match = evaluate_exact_match(ground_truth, prediction)\n",
    "  exM += int(exact_match)\n",
    "  print(\"##### example {}: #####\".format(i))\n",
    "  print(prediction)\n",
    "  print(\"f1 score: \",f1_score)\n",
    "  print(\"exact_match: \",int(exact_match),\"\\n\")\n",
    "  print(\"#########\\n\")\n",
    "\n",
    "print(\"{}  moyenne de F1 - Score\".format(f/25))\n",
    "print(\"{} % moyenne de Exact Match - Score\".format((exM/25)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "13Fy9Tvntimq"
   },
   "source": [
    "meuilleur_formulation (head_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2W6XdlNFs3qJ",
    "outputId": "118875fe-34c3-401a-dee2-b0b43d703b44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### example 0: #####\n",
      "standing on the ground checking the depth of the cut into the asphalt\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 1: #####\n",
      "\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 2: #####\n",
      "seizure\n",
      "f1 score:  0.4\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 3: #####\n",
      "he was struck by the cement mixer that tipped over in the process of mixing cement / concrete\n",
      "f1 score:  0.5714285714285715\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 4: #####\n",
      "the semi - truck swerved to miss a car at employee # 1 ' s sign area and struck employee # 1\n",
      "f1 score:  0.3157894736842105\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 5: #####\n",
      "employee # 1 was killed\n",
      "f1 score:  0.3333333333333333\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 6: #####\n",
      "the employee moved and his left foot was struck by and run over by a loader\n",
      "f1 score:  0.88\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 7: #####\n",
      "a tractor - trailer unit was parked in the adjacent bay and there was a gap of approximately 2 to 3 ft between the trailer and the loading dock frame\n",
      "f1 score:  0.3684210526315789\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 8: #####\n",
      "\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 9: #####\n",
      "the car suddenly descended a few inches severing employee # 1 ' s right big toe\n",
      "f1 score:  0.5882352941176471\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 10: #####\n",
      "the employees took a work break\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 11: #####\n",
      "employee # 1 was placing the additional support brace on top of the bottle jack in the upward position\n",
      "f1 score:  0.3478260869565218\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 12: #####\n",
      "the north wall\n",
      "f1 score:  0.25\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 13: #####\n",
      "a separation between some previously laid pipe\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 14: #####\n",
      "the trusses collapsed causing them to fall\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 15: #####\n",
      "the trench wall and spoil pile collapsed\n",
      "f1 score:  0.8\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 16: #####\n",
      "the wall caved in on him\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 17: #####\n",
      "\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 18: #####\n",
      "the entire east side caved in and buried employee # 1\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 19: #####\n",
      "\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 20: #####\n",
      "employee # 1 had accessed a hopper barge to release a cable that had been used to support the barge on the starboard side\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 21: #####\n",
      "employee # 1 became separated from his life jacket\n",
      "f1 score:  0.22222222222222224\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 22: #####\n",
      "a rain storm flooded the pipe drowning employee # 1\n",
      "f1 score:  0.6\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 23: #####\n",
      "drowned\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 24: #####\n",
      "a diver became caught in a coffer dam and drowned\n",
      "f1 score:  0.2222222222222222\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "number correct EVENT :2\n",
      "8.0 % correct answers\n",
      "0.3959791302638523  moyenne de F1 - Score\n",
      "16.0 % moyenne de Exact Match - Score\n"
     ]
    }
   ],
   "source": [
    "s = 0\n",
    "f=0\n",
    "exM=0\n",
    "#\"What was happening after what occured in the place where was it done?\"\n",
    "#\"What was happening at the end?\" 38%\n",
    "#\"What the most thing that was happening and marking the story  at the end?\"  31%\n",
    "# \"What the most thing that was happening and marking the story?\" 31%\n",
    "#\"What the most thing that was happening  in the story?\" 31%\n",
    "#\"What the most thing that was happening?\" 43.83 (the most > 43.27)\n",
    "# \"What is the most controversial thing that happened?\" (46%)\n",
    "# \"What is the worst and risky thing happening?\" 47.88%\n",
    "#\"What is the  most astonishing thing happening?\"  head_only  (41%  16%) |  (head + tail) 50.61%   24%  | 54.61%  28% (head + tail + head_4 + tail_4)\n",
    "for i in range(len(data)):\n",
    "  text_data = data[i]['text']\n",
    "  ground_truth = data[i][\"EVENT\"]\n",
    "  question,text = \"What is the  most astonishing thing happening?\",text_data\n",
    "\n",
    "  chunk_size = 512\n",
    "  head_only = text[:chunk_size]\n",
    "  head = text[:chunk_size//2]\n",
    "  tail = text[-chunk_size//2:]\n",
    "\n",
    "  head_2 = text[chunk_size:chunk_size+ 513]\n",
    "  tail_2 = text[chunk_size + 512: chunk_size + 1024]\n",
    "\n",
    "  head_3 = text[chunk_size + 1024: chunk_size + 1536]\n",
    "  tail_3 = text[chunk_size + 1536: chunk_size + 2048]\n",
    "\n",
    "  head_4 = text[chunk_size + 2048: chunk_size + 256]\n",
    "  tail_4 = text[chunk_size + 2560: chunk_size + 3071]\n",
    "\n",
    "  tail_only = text[-chunk_size:]\n",
    "  inputs = tokenizer(question, head_only , return_tensors=\"pt\")\n",
    "  with torch.no_grad():\n",
    "      outputs = model(**inputs)\n",
    "\n",
    "  answer_start_index = outputs.start_logits.argmax()\n",
    "  answer_end_index = outputs.end_logits.argmax()\n",
    "\n",
    "  predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "  prediction = tokenizer.decode(predict_answer_tokens, skip_special_tokens=True)\n",
    "\n",
    "  When_part = data[i][\"EVENT\"]\n",
    "  f1_score = evaluate_f1(ground_truth, prediction)\n",
    "  f+=f1_score\n",
    "  exact_match = evaluate_exact_match(ground_truth, prediction)\n",
    "  exM += int(exact_match)\n",
    "  print(\"##### example {}: #####\".format(i))\n",
    "  print(prediction)\n",
    "  print(\"f1 score: \",f1_score)\n",
    "  print(\"exact_match: \",int(exact_match),\"\\n\")\n",
    "  print(\"#########\\n\")\n",
    "  if prediction == When_part.lower():\n",
    "    s+=1\n",
    "percenantage = (s/25)*100\n",
    "print(\"number correct EVENT :{}\".format(s))\n",
    "print(\"{} % correct answers\".format(percenantage))\n",
    "print(\"{}  moyenne de F1 - Score\".format(f/25))\n",
    "print(\"{} % moyenne de Exact Match - Score\".format((exM/25)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTyjGx92t1no"
   },
   "source": [
    "meuilleur_formulation (head+tail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "anGhGG_3t6kp",
    "outputId": "998f6b70-f62f-44f5-a1e6-f76224d0ae63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### example 0: #####\n",
      "\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 1: #####\n",
      "employee # 1 suffered a serious fracture injury to his left leg\n",
      "f1 score:  0.16\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 2: #####\n",
      "employee # 1 had a seizure\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 3: #####\n",
      "he was struck by the cement mixer that tipped over in the process of mixing cement / concrete\n",
      "f1 score:  0.5714285714285715\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 4: #####\n",
      "employee # 1 was killed\n",
      "f1 score:  0.5714285714285715\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 5: #####\n",
      "employee # 1 was killed\n",
      "f1 score:  0.3333333333333333\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 6: #####\n",
      "the employee moved and his left foot was struck by and run over by a loader\n",
      "f1 score:  0.88\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 7: #####\n",
      "he suffered a fractured pelvis a ruptured bladder and leg vein damage\n",
      "f1 score:  0.08333333333333333\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 8: #####\n",
      "employee # 1 was killed\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 9: #####\n",
      "the car suddenng employee # 1 ' s right big toe\n",
      "f1 score:  0.15384615384615385\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 10: #####\n",
      "cancame entangled in a sheet of plastic and was unable to break free when stub pier \" c. 1 - 0. 3 \" a 14 - foot tall masonry pier collapsed on him crushing him\n",
      "f1 score:  0.42105263157894735\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 11: #####\n",
      "the carport structure shifted off the temporary supports trapping employee # 1 on the inside structure of the carport breaking his neck\n",
      "f1 score:  0.6399999999999999\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 12: #####\n",
      "crushing employee # 1 against the south wall\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 13: #####\n",
      "employee # 1 was killed when buried\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 14: #####\n",
      "the trusses collapsed causing them to fall\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 15: #####\n",
      "employee # 1 was installing a 2 - inch water line and tracer wire in the trench which meee # 1 was trapped for approximately 6 to 8 minutes and was unconscious\n",
      "f1 score:  0.2222222222222222\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 16: #####\n",
      "the wall caved in on him\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 17: #####\n",
      "he lost control of it\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 18: #####\n",
      "the entire east side caved in and buried ed\n",
      "f1 score:  0.823529411764706\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 19: #####\n",
      "an engineered tension crack which increased the angle of internal friction and shear strength of the wall\n",
      "f1 score:  0.11111111111111112\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 20: #####\n",
      "the barge capsized employee # 1 was caught in the hopper section trapping him under the barge and he drowned\n",
      "f1 score:  0.2222222222222222\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 21: #####\n",
      "employee # 1 sank and drowned\n",
      "f1 score:  0.6666666666666666\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 22: #####\n",
      "a rain storm flooded the pipe drowning employee # 1\n",
      "f1 score:  0.6\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 23: #####\n",
      "drowned\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 24: #####\n",
      "employee # 1 a diver became caught in a coffer dam and drowned\n",
      "f1 score:  0.18181818181818182\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "number correct EVENT :2\n",
      "8.0 % correct answers\n",
      "0.5056796964301608  moyenne de F1 - Score\n",
      "24.0 % moyenne de Exact Match - Score\n"
     ]
    }
   ],
   "source": [
    "s = 0\n",
    "f=0\n",
    "exM=0\n",
    "#\"What was happening after what occured in the place where was it done?\"\n",
    "#\"What was happening at the end?\" 38%\n",
    "#\"What the most thing that was happening and marking the story  at the end?\"  31%\n",
    "# \"What the most thing that was happening and marking the story?\" 31%\n",
    "#\"What the most thing that was happening  in the story?\" 31%\n",
    "#\"What the most thing that was happening?\" 43.83 (the most > 43.27)\n",
    "# \"What is the most controversial thing that happened?\" (46%)\n",
    "# \"What is the worst and risky thing happening?\" 47.88%\n",
    "#\"What is the  most astonishing thing happening?\"  head_only  (41%  16%) |  (head + tail) 50.61%   24%  | 54.61%  28% (head + tail + head_4 + tail_4)\n",
    "for i in range(len(data)):\n",
    "  text_data = data[i]['text']\n",
    "  ground_truth = data[i][\"EVENT\"]\n",
    "  question,text = \"What is the  most astonishing thing happening?\",text_data\n",
    "\n",
    "  chunk_size = 512\n",
    "  head_only = text[:chunk_size]\n",
    "  head = text[:chunk_size//2]\n",
    "  tail = text[-chunk_size//2:]\n",
    "\n",
    "  head_2 = text[chunk_size:chunk_size+ 513]\n",
    "  tail_2 = text[chunk_size + 512: chunk_size + 1024]\n",
    "\n",
    "  head_3 = text[chunk_size + 1024: chunk_size + 1536]\n",
    "  tail_3 = text[chunk_size + 1536: chunk_size + 2048]\n",
    "\n",
    "  head_4 = text[chunk_size + 2048: chunk_size + 256]\n",
    "  tail_4 = text[chunk_size + 2560: chunk_size + 3071]\n",
    "\n",
    "  tail_only = text[-chunk_size:]\n",
    "  inputs = tokenizer(question, head + tail , return_tensors=\"pt\")\n",
    "  with torch.no_grad():\n",
    "      outputs = model(**inputs)\n",
    "\n",
    "  answer_start_index = outputs.start_logits.argmax()\n",
    "  answer_end_index = outputs.end_logits.argmax()\n",
    "\n",
    "  predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "  prediction = tokenizer.decode(predict_answer_tokens, skip_special_tokens=True)\n",
    "\n",
    "  When_part = data[i][\"EVENT\"]\n",
    "  f1_score = evaluate_f1(ground_truth, prediction)\n",
    "  f+=f1_score\n",
    "  exact_match = evaluate_exact_match(ground_truth, prediction)\n",
    "  exM += int(exact_match)\n",
    "  print(\"##### example {}: #####\".format(i))\n",
    "  print(prediction)\n",
    "  print(\"f1 score: \",f1_score)\n",
    "  print(\"exact_match: \",int(exact_match),\"\\n\")\n",
    "  print(\"#########\\n\")\n",
    "  if prediction == When_part.lower():\n",
    "    s+=1\n",
    "percenantage = (s/25)*100\n",
    "print(\"number correct EVENT :{}\".format(s))\n",
    "print(\"{} % correct answers\".format(percenantage))\n",
    "print(\"{}  moyenne de F1 - Score\".format(f/25))\n",
    "print(\"{} % moyenne de Exact Match - Score\".format((exM/25)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P0iQVforuIaU"
   },
   "source": [
    "meuilleur formulation avec (head + tail +head_4 + tail_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7LNT4wFCOBvx",
    "outputId": "593f9a9c-f602-4d00-8be9-508d834fa42b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### example 0: #####\n",
      "employee # 1 was struck and thrown\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 1: #####\n",
      "employee # 1 suffered a serious fracture injury to his left leg\n",
      "f1 score:  0.16\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 2: #####\n",
      "employee # 1 had a seizure\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 3: #####\n",
      "he was struck by the cement mixer that tipped over in the process of mixing cement / concrete\n",
      "f1 score:  0.5714285714285715\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 4: #####\n",
      "employee # 1 was killed\n",
      "f1 score:  0.5714285714285715\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 5: #####\n",
      "employee # 1 was killed\n",
      "f1 score:  0.3333333333333333\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 6: #####\n",
      "the employee moved and his left foot was struck by and run over by a loader\n",
      "f1 score:  0.88\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 7: #####\n",
      "he suffered a fractured pelvis a ruptured bladder and leg vein damage\n",
      "f1 score:  0.08333333333333333\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 8: #####\n",
      "employee # 1 was killed\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 9: #####\n",
      "the car suddenng employee # 1 ' s right big toe\n",
      "f1 score:  0.15384615384615385\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 10: #####\n",
      "cancame entangled in a sheet of plastic and was unable to break free when stub pier \" c. 1 - 0. 3 \" a 14 - foot tall masonry pier collapsed on him crushing him\n",
      "f1 score:  0.42105263157894735\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 11: #####\n",
      "the carport structure shifted off the temporary supports trapping employee # 1 on the inside structure of the carport breaking his neck\n",
      "f1 score:  0.6399999999999999\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 12: #####\n",
      "crushing employee # 1 against the south wall\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 13: #####\n",
      "employee # 1 was killed when buried\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 14: #####\n",
      "the trusses collapsed causing them to fall\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 15: #####\n",
      "employee # 1 was installing a 2 - inch water line and tracer wire in the trench which meee # 1 was trapped for approximately 6 to 8 minutes and was unconscious\n",
      "f1 score:  0.2222222222222222\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 16: #####\n",
      "the wall caved in on him\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 17: #####\n",
      "he lost control of it\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 18: #####\n",
      "the entire east side caved in and buried ed\n",
      "f1 score:  0.823529411764706\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 19: #####\n",
      "an engineered tension crack which increased the angle of internal friction and shear strength of the wall\n",
      "f1 score:  0.11111111111111112\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 20: #####\n",
      "the barge capsized employee # 1 was caught in the hopper section trapping him under the barge and he drowned\n",
      "f1 score:  0.2222222222222222\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 21: #####\n",
      "employee # 1 sank and drowned\n",
      "f1 score:  0.6666666666666666\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 22: #####\n",
      "a rain storm flooded the pipe drowning employee # 1\n",
      "f1 score:  0.6\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 23: #####\n",
      "drowned\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 24: #####\n",
      "employee # 1 a diver became caught in a coffer dam and drowned\n",
      "f1 score:  0.18181818181818182\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "number correct EVENT :2\n",
      "8.0 % correct answers\n",
      "0.5456796964301608  moyenne de F1 - Score\n",
      "28.000000000000004 % moyenne de Exact Match - Score\n"
     ]
    }
   ],
   "source": [
    "s = 0\n",
    "f=0\n",
    "exM=0\n",
    "#\"What was happening after what occured in the place where was it done?\"\n",
    "#\"What was happening at the end?\" 38%\n",
    "#\"What the most thing that was happening and marking the story  at the end?\"  31%\n",
    "# \"What the most thing that was happening and marking the story?\" 31%\n",
    "#\"What the most thing that was happening  in the story?\" 31%\n",
    "#\"What the most thing that was happening?\" 43.83 (the most > 43.27)\n",
    "# \"What is the most controversial thing that happened?\" (46%)\n",
    "# \"What is the worst and risky thing happening?\" 47.88%\n",
    "#\"What is the  most astonishing thing happening?\"  head_only  (41%  16%) |  (head + tail) 50.61%   24%  | 54.61%  28% (head + tail + head_4 + tail_4)\n",
    "for i in range(len(data)):\n",
    "  text_data = data[i]['text']\n",
    "  ground_truth = data[i][\"EVENT\"]\n",
    "  question,text = \"What is the most controversial thing that happened?\",text_data\n",
    "\n",
    "  chunk_size = 512\n",
    "  head_only = text[:chunk_size]\n",
    "  head = text[:chunk_size//2]\n",
    "  tail = text[-chunk_size//2:]\n",
    "\n",
    "  head_2 = text[chunk_size:chunk_size+ 513]\n",
    "  tail_2 = text[chunk_size + 512: chunk_size + 1024]\n",
    "\n",
    "  head_3 = text[chunk_size + 1024: chunk_size + 1536]\n",
    "  tail_3 = text[chunk_size + 1536: chunk_size + 2048]\n",
    "\n",
    "  head_4 = text[chunk_size + 2048: chunk_size + 256]\n",
    "  tail_4 = text[chunk_size + 2560: chunk_size + 3071]\n",
    "\n",
    "  tail_only = text[-chunk_size:]\n",
    "  inputs = tokenizer(question, head + tail + head_4 + tail_4, return_tensors=\"pt\")\n",
    "  with torch.no_grad():\n",
    "      outputs = model(**inputs)\n",
    "\n",
    "  answer_start_index = outputs.start_logits.argmax()\n",
    "  answer_end_index = outputs.end_logits.argmax()\n",
    "\n",
    "  predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "  prediction = tokenizer.decode(predict_answer_tokens, skip_special_tokens=True)\n",
    "\n",
    "  When_part = data[i][\"EVENT\"]\n",
    "  f1_score = evaluate_f1(ground_truth, prediction)\n",
    "  f+=f1_score\n",
    "  exact_match = evaluate_exact_match(ground_truth, prediction)\n",
    "  exM += int(exact_match)\n",
    "  print(\"##### example {}: #####\".format(i))\n",
    "  print(prediction)\n",
    "  print(\"f1 score: \",f1_score)\n",
    "  print(\"exact_match: \",int(exact_match),\"\\n\")\n",
    "  print(\"#########\\n\")\n",
    "  if prediction == When_part.lower():\n",
    "    s+=1\n",
    "percenantage = (s/25)*100\n",
    "print(\"number correct EVENT :{}\".format(s))\n",
    "print(\"{} % correct answers\".format(percenantage))\n",
    "print(\"{}  moyenne de F1 - Score\".format(f/25))\n",
    "print(\"{} % moyenne de Exact Match - Score\".format((exM/25)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zLSTKof2ugvf"
   },
   "source": [
    "2eme formulation (head + tail +head_4 + tail_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wgN7LTyMz1Y1",
    "outputId": "2140bd8c-0c93-4ff9-dcb2-01aa6cfa775f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### example 0: #####\n",
      "employee # 1 was struck and thrown\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 1: #####\n",
      "demolish the interiors of the building. they scraped the interiors of the building and collected debris asemployee # 1 ' s left foot. employee # 1 suffered a serious fracture injury to his left leg and was hospitalized\n",
      "f1 score:  0.17777777777777776\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 2: #####\n",
      "paramedics arrived\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 3: #####\n",
      "tipped over\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 4: #####\n",
      "\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 5: #####\n",
      "the passenger vehicle struck the trailered equipment and employee # 1. employee # 1 was killed.\n",
      "f1 score:  0.8\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 6: #####\n",
      "the employee underwent surgery for a crushed left foot\n",
      "f1 score:  0.2222222222222222\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 7: #####\n",
      "\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 8: #####\n",
      "he was walking west across the on - ramp to remove another barrel and was struck by the dump truck\n",
      "f1 score:  0.38095238095238093\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 9: #####\n",
      "the car suddenng employee # 1 ' s right big toe\n",
      "f1 score:  0.15384615384615385\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 10: #####\n",
      "stub pier \" c. 1 - 0. 3 \" a 14 - foot tall masonry pier collapsed on him crushing him\n",
      "f1 score:  0.64\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 11: #####\n",
      "the carport structure shifted off the temporary supports trapping employee # 1 on the inside structure of the carport breaking his neck\n",
      "f1 score:  0.6399999999999999\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 12: #####\n",
      "crushing employee # 1 against the south wall\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 13: #####\n",
      "employee # 1 was killed when buried\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 14: #####\n",
      "the trusses started buckling\n",
      "f1 score:  0.2222222222222222\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 15: #####\n",
      "\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 16: #####\n",
      "the local fire and ambulance service arrived and removed emp\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 17: #####\n",
      "the wall was too heavy for one person and when it bumped up against a ceiling pipe while being raised he lost control of it\n",
      "f1 score:  0.07142857142857142\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 18: #####\n",
      "the entire east side caved in and buried ed\n",
      "f1 score:  0.823529411764706\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 19: #####\n",
      "municipal tie - in point\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 20: #####\n",
      "the barge capsized employee # 1 was caught in the hopper section trapping him under the barge and he drowned\n",
      "f1 score:  0.2222222222222222\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 21: #####\n",
      "employee # 1 sank and drowned\n",
      "f1 score:  0.6666666666666666\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 22: #####\n",
      "a rain storm flooded the pipe drowning employee # 1\n",
      "f1 score:  0.6\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 23: #####\n",
      "drowned\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 24: #####\n",
      "drowned\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "number correct EVENT :2\n",
      "8.0 % correct answers\n",
      "0.4248347051641169  moyenne de F1 - Score\n",
      "20.0 % moyenne de Exact Match - Score\n"
     ]
    }
   ],
   "source": [
    "s = 0\n",
    "f=0\n",
    "exM=0\n",
    "#\"What was happening after what occured in the place where was it done?\"\n",
    "#\"What was happening at the end?\" 38%\n",
    "#\"What the most thing that was happening and marking the story  at the end?\"  31%\n",
    "# \"What the most thing that was happening and marking the story?\" 31%\n",
    "#\"What the most thing that was happening  in the story?\" 31%\n",
    "#\"What the most thing that was happening?\" 43.83 (the most > 43.27)\n",
    "# \"What is the most controversial thing that happened?\" (46%)\n",
    "# \"What is the worst and risky thing happening?\" 47.88%\n",
    "#\"What is the  most astonishing thing happening?\"  head_only  (41%  16%) |  (head + tail) 50.61%   24%  | 54.61%  28% (head + tail + head_4 + tail_4)\n",
    "for i in range(len(data)):\n",
    "  text_data = data[i]['text']\n",
    "  ground_truth = data[i][\"EVENT\"]\n",
    "  question,text = \"What was happening at the end?\",text_data\n",
    "\n",
    "\n",
    "  text_essay = text[256:256+512]\n",
    "  chunk_size = 512\n",
    "  head_only = text[:chunk_size]\n",
    "  head = text[:chunk_size//2]\n",
    "  tail = text[-chunk_size//2:]\n",
    "\n",
    "  head_2 = text[chunk_size:chunk_size+ 513]\n",
    "  tail_2 = text[chunk_size + 512: chunk_size + 1024]\n",
    "\n",
    "  head_3 = text[chunk_size + 1024: chunk_size + 1536]\n",
    "  tail_3 = text[chunk_size + 1536: chunk_size + 2048]\n",
    "\n",
    "  head_4 = text[chunk_size + 2048: chunk_size + 256]\n",
    "  tail_4 = text[chunk_size + 2560: chunk_size + 3071]\n",
    "\n",
    "  tail_only = text[-chunk_size:]\n",
    "  inputs = tokenizer(question, head + tail + head_4 + tail_4, return_tensors=\"pt\")\n",
    "  with torch.no_grad():\n",
    "      outputs = model(**inputs)\n",
    "\n",
    "  answer_start_index = outputs.start_logits.argmax()\n",
    "  answer_end_index = outputs.end_logits.argmax()\n",
    "\n",
    "  predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "  prediction = tokenizer.decode(predict_answer_tokens, skip_special_tokens=True)\n",
    "\n",
    "  When_part = data[i][\"EVENT\"]\n",
    "  f1_score = evaluate_f1(ground_truth, prediction)\n",
    "  f+=f1_score\n",
    "  exact_match = evaluate_exact_match(ground_truth, prediction)\n",
    "  exM += int(exact_match)\n",
    "  print(\"##### example {}: #####\".format(i))\n",
    "  print(prediction)\n",
    "  print(\"f1 score: \",f1_score)\n",
    "  print(\"exact_match: \",int(exact_match),\"\\n\")\n",
    "  print(\"#########\\n\")\n",
    "  if prediction == When_part.lower():\n",
    "    s+=1\n",
    "percenantage = (s/25)*100\n",
    "print(\"number correct EVENT :{}\".format(s))\n",
    "print(\"{} % correct answers\".format(percenantage))\n",
    "print(\"{}  moyenne de F1 - Score\".format(f/25))\n",
    "print(\"{} % moyenne de Exact Match - Score\".format((exM/25)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gAEUtCmsuwSx"
   },
   "source": [
    "1ère formulation (head + tail + head_4 + tail_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ErqZ3YrJu3Ha",
    "outputId": "298d21f6-ed12-4ed5-f8a6-2020e531c8b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### example 0: #####\n",
      "employee # 1 was struck and thrown\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 1: #####\n",
      "demolish the interiors of the building. they scraped the interiors of the building and collected debris asemployee # 1 ' s left foot. employee # 1 suffered a serious fracture injury to his left leg and was hospitalized\n",
      "f1 score:  0.17777777777777776\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 2: #####\n",
      "paramedics arrived\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 3: #####\n",
      "tipped over\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 4: #####\n",
      "\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 5: #####\n",
      "the passenger vehicle struck the trailered equipment and employee # 1. employee # 1 was killed.\n",
      "f1 score:  0.8\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 6: #####\n",
      "the employee underwent surgery for a crushed left foot\n",
      "f1 score:  0.2222222222222222\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 7: #####\n",
      "\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 8: #####\n",
      "he was walking west across the on - ramp to remove another barrel and was struck by the dump truck\n",
      "f1 score:  0.38095238095238093\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 9: #####\n",
      "the car suddenng employee # 1 ' s right big toe\n",
      "f1 score:  0.15384615384615385\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 10: #####\n",
      "stub pier \" c. 1 - 0. 3 \" a 14 - foot tall masonry pier collapsed on him crushing him\n",
      "f1 score:  0.64\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 11: #####\n",
      "the carport structure shifted off the temporary supports trapping employee # 1 on the inside structure of the carport breaking his neck\n",
      "f1 score:  0.6399999999999999\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 12: #####\n",
      "crushing employee # 1 against the south wall\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 13: #####\n",
      "employee # 1 was killed when buried\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 14: #####\n",
      "the trusses started buckling\n",
      "f1 score:  0.2222222222222222\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 15: #####\n",
      "\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 16: #####\n",
      "the local fire and ambulance service arrived and removed emp\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 17: #####\n",
      "the wall was too heavy for one person and when it bumped up against a ceiling pipe while being raised he lost control of it\n",
      "f1 score:  0.07142857142857142\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 18: #####\n",
      "the entire east side caved in and buried ed\n",
      "f1 score:  0.823529411764706\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 19: #####\n",
      "municipal tie - in point\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 20: #####\n",
      "the barge capsized employee # 1 was caught in the hopper section trapping him under the barge and he drowned\n",
      "f1 score:  0.2222222222222222\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 21: #####\n",
      "employee # 1 sank and drowned\n",
      "f1 score:  0.6666666666666666\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 22: #####\n",
      "a rain storm flooded the pipe drowning employee # 1\n",
      "f1 score:  0.6\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 23: #####\n",
      "drowned\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 24: #####\n",
      "drowned\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "number correct EVENT :2\n",
      "8.0 % correct answers\n",
      "0.4248347051641169  moyenne de F1 - Score\n",
      "20.0 % moyenne de Exact Match - Score\n"
     ]
    }
   ],
   "source": [
    "s = 0\n",
    "f=0\n",
    "exM=0\n",
    "#\"What was happening after what occured in the place where was it done?\"\n",
    "#\"What was happening at the end?\" 38%\n",
    "#\"What the most thing that was happening and marking the story  at the end?\"  31%\n",
    "# \"What the most thing that was happening and marking the story?\" 31%\n",
    "#\"What the most thing that was happening  in the story?\" 31%\n",
    "#\"What the most thing that was happening?\" 43.83 (the most > 43.27)\n",
    "# \"What is the most controversial thing that happened?\" (46%)\n",
    "# \"What is the worst and risky thing happening?\" 47.88%\n",
    "#\"What is the  most astonishing thing happening?\"  head_only  (41%  16%) |  (head + tail) 50.61%   24%  | 54.61%  28% (head + tail + head_4 + tail_4)\n",
    "for i in range(len(data)):\n",
    "  text_data = data[i]['text']\n",
    "  ground_truth = data[i][\"EVENT\"]\n",
    "  question,text = \"What was happening at the end?\",text_data\n",
    "\n",
    "\n",
    "  text_essay = text[256:256+512]\n",
    "  chunk_size = 512\n",
    "  head_only = text[:chunk_size]\n",
    "  head = text[:chunk_size//2]\n",
    "  tail = text[-chunk_size//2:]\n",
    "\n",
    "  head_2 = text[chunk_size:chunk_size+ 513]\n",
    "  tail_2 = text[chunk_size + 512: chunk_size + 1024]\n",
    "\n",
    "  head_3 = text[chunk_size + 1024: chunk_size + 1536]\n",
    "  tail_3 = text[chunk_size + 1536: chunk_size + 2048]\n",
    "\n",
    "  head_4 = text[chunk_size + 2048: chunk_size + 256]\n",
    "  tail_4 = text[chunk_size + 2560: chunk_size + 3071]\n",
    "\n",
    "  tail_only = text[-chunk_size:]\n",
    "  inputs = tokenizer(question, head + tail + head_4 + tail_4, return_tensors=\"pt\")\n",
    "  with torch.no_grad():\n",
    "      outputs = model(**inputs)\n",
    "\n",
    "  answer_start_index = outputs.start_logits.argmax()\n",
    "  answer_end_index = outputs.end_logits.argmax()\n",
    "\n",
    "  predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "  prediction = tokenizer.decode(predict_answer_tokens, skip_special_tokens=True)\n",
    "\n",
    "  When_part = data[i][\"EVENT\"]\n",
    "  f1_score = evaluate_f1(ground_truth, prediction)\n",
    "  f+=f1_score\n",
    "  exact_match = evaluate_exact_match(ground_truth, prediction)\n",
    "  exM += int(exact_match)\n",
    "  print(\"##### example {}: #####\".format(i))\n",
    "  print(prediction)\n",
    "  print(\"f1 score: \",f1_score)\n",
    "  print(\"exact_match: \",int(exact_match),\"\\n\")\n",
    "  print(\"#########\\n\")\n",
    "  if prediction == When_part.lower():\n",
    "    s+=1\n",
    "percenantage = (s/25)*100\n",
    "print(\"number correct EVENT :{}\".format(s))\n",
    "print(\"{} % correct answers\".format(percenantage))\n",
    "print(\"{}  moyenne de F1 - Score\".format(f/25))\n",
    "print(\"{} % moyenne de Exact Match - Score\".format((exM/25)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w9IqLLywR0r0",
    "outputId": "35a22330-5886-4b89-b903-0fe2eb224a28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### example 0: #####\n",
      "standing on the ground checking the depth of the cut into the asphalt\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 1: #####\n",
      "when the job assignment was finish\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 2: #####\n",
      "paramedics arrived\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 3: #####\n",
      "tipped over\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 4: #####\n",
      "its brakes locked up leaving residue on the roadway. then the semi - truck swerved to miss a car at employee # 1 ' s sign area and struck employee # 1\n",
      "f1 score:  0.21428571428571425\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 5: #####\n",
      "a driver of a passenger vehicle fell asleep while driving and crossed three lanes of traffic\n",
      "f1 score:  0.2727272727272727\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 6: #####\n",
      "the employee moved and his left foot was struck by and run over by a loader\n",
      "f1 score:  0.88\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 7: #####\n",
      "a tractor - trailer unit was parked in the adjacent bay and there was a gap of approximately 2 to 3 ft between the trailer and the loading dock frame\n",
      "f1 score:  0.3684210526315789\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 8: #####\n",
      "\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 9: #####\n",
      "the car suddenly descended a few inches severing employee # 1 ' s right big toe\n",
      "f1 score:  0.5882352941176471\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 10: #####\n",
      "finish the exterior insulating finishing system on the spandrel panels at the garden center\n",
      "f1 score:  0.09999999999999999\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 11: #####\n",
      "employee # 1 was placing the additional support brace on top of the bottle jack in the upward position\n",
      "f1 score:  0.3478260869565218\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 12: #####\n",
      "cement slurry backfill was being poured between the excavation wall and the north wall of the inlet structure\n",
      "f1 score:  0.09523809523809522\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 13: #####\n",
      "a separation between some previously laid pipe and had his crew pull out the affected sections of pipe\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 14: #####\n",
      "\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 15: #####\n",
      "the trench wall and spoil pile collapsed\n",
      "f1 score:  0.8\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 16: #####\n",
      "the local fire and ambulance service arrived and removed employee # 1 from the trench\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 17: #####\n",
      "the wall was too heavy for one person and when it bumped up against a ceiling pipe while being raised he lost control of it\n",
      "f1 score:  0.07142857142857142\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 18: #####\n",
      "the entire east side caved in and buried employee # 1\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 19: #####\n",
      "checking the fall angle of the lateral and connecting gasket joints with grease\n",
      "f1 score:  0.13333333333333333\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 20: #####\n",
      "another 10 ft by 20 ft section attached\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 21: #####\n",
      "his fall arrest lanyard became tangled on a mooring post. employee # 1 lost his balance and fell from the east - most barge into the 50 - degree fahrenheit water of nickajack lake. while in the water employee # 1 became separated from his life jacket\n",
      "f1 score:  0.2448979591836735\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 22: #####\n",
      "a rain storm flooded the pipe drowning employee # 1\n",
      "f1 score:  0.6\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 23: #####\n",
      "drowned\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 24: #####\n",
      "drowned\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "0.3086557351960964  moyenne de F1 - Score\n",
      "12.0 % moyenne de Exact Match - Score\n"
     ]
    }
   ],
   "source": [
    "s = 0\n",
    "f=0\n",
    "exM=0\n",
    "#\"What was happening after what occured in the place where was it done?\"\n",
    "#\"What was happening at the end?\" 38%\n",
    "#\"What the most thing that was happening and marking the story  at the end?\"  31%\n",
    "# \"What the most thing that was happening and marking the story?\" 31%\n",
    "#\"What the most thing that was happening  in the story?\" 31%\n",
    "#\"What the most thing that was happening?\" 43.83 (the most > 43.27)\n",
    "# \"What is the most controversial thing that happened?\" (46%)\n",
    "# \"What is the worst and risky thing happening?\" 47.88%\n",
    "#\"What is the  most astonishing thing happening?\"  head_only  (41%  16%) |  (head + tail) 50.61%   24%  | 54.61%  28% (head + tail + head_4 + tail_4)\n",
    "for i in range(len(data)):\n",
    "  text_data = data[i]['text']\n",
    "  ground_truth = data[i][\"EVENT\"]\n",
    "  question,text = \"What was happening at the end?\",text_data\n",
    "\n",
    "\n",
    "  text_essay = text[256:256+512]\n",
    "  chunk_size = 512\n",
    "  head_only = text[:chunk_size]\n",
    "  head = text[:chunk_size//2]\n",
    "  tail = text[-chunk_size//2:]\n",
    "\n",
    "  head_2 = text[chunk_size:chunk_size+ 513]\n",
    "  tail_2 = text[chunk_size + 512: chunk_size + 1024]\n",
    "\n",
    "  head_3 = text[chunk_size + 1024: chunk_size + 1536]\n",
    "  tail_3 = text[chunk_size + 1536: chunk_size + 2048]\n",
    "\n",
    "  head_4 = text[chunk_size + 2048: chunk_size + 256]\n",
    "  tail_4 = text[chunk_size + 2560: chunk_size + 3071]\n",
    "\n",
    "  tail_only = text[-chunk_size:]\n",
    "  inputs = tokenizer(question, head_only, return_tensors=\"pt\")\n",
    "  with torch.no_grad():\n",
    "      outputs = model(**inputs)\n",
    "\n",
    "  answer_start_index = outputs.start_logits.argmax()\n",
    "  answer_end_index = outputs.end_logits.argmax()\n",
    "\n",
    "  predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "  prediction = tokenizer.decode(predict_answer_tokens, skip_special_tokens=True)\n",
    "\n",
    "  When_part = data[i][\"EVENT\"]\n",
    "  f1_score = evaluate_f1(ground_truth, prediction)\n",
    "  f+=f1_score\n",
    "  exact_match = evaluate_exact_match(ground_truth, prediction)\n",
    "  exM += int(exact_match)\n",
    "  print(\"##### example {}: #####\".format(i))\n",
    "  print(prediction)\n",
    "  print(\"f1 score: \",f1_score)\n",
    "  print(\"exact_match: \",int(exact_match),\"\\n\")\n",
    "  print(\"#########\\n\")\n",
    "\n",
    "print(\"{}  moyenne de F1 - Score\".format(f/25))\n",
    "print(\"{} % moyenne de Exact Match - Score\".format((exM/25)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UidKby0UR9qw",
    "outputId": "c17f9d6e-8836-4af1-99f6-522cd98dcf93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### example 0: #####\n",
      "grind out existing asphalt from an interstate at a railroad bridge\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 1: #####\n",
      "demolish the interiors of the building. they scraped the interiors of the building and collected debris asemployee # 1 ' s left foot. employee # 1 suffered a serious fracture injury to his left leg and was hospitalized\n",
      "f1 score:  0.17777777777777776\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 2: #####\n",
      "paramedics arrived\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 3: #####\n",
      "tipped over\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 4: #####\n",
      "\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 5: #####\n",
      "the passenger vehicle struck the trailered equipment and employee # 1. employee # 1 was killed.\n",
      "f1 score:  0.8\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 6: #####\n",
      "the employee underwent surgery for a crushed left foot\n",
      "f1 score:  0.2222222222222222\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 7: #####\n",
      "\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 8: #####\n",
      "he was walking west across the on - ramp to remove another barrel and was struck by the dump truck\n",
      "f1 score:  0.38095238095238093\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 9: #####\n",
      "the car suddenng employee # 1 ' s right big toe\n",
      "f1 score:  0.15384615384615385\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 10: #####\n",
      "stub pier \" c. 1 - 0. 3 \" a 14 - foot tall masonry pier collapsed on him crushing him\n",
      "f1 score:  0.64\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 11: #####\n",
      "the carport structure shifted off the temporary supports trapping employee # 1 on the inside structure of the carport breaking his neck\n",
      "f1 score:  0.6399999999999999\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 12: #####\n",
      "crushing employee # 1 against the south wall\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 13: #####\n",
      "employee # 1 was killed when buried\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 14: #####\n",
      "the trusses started buckling\n",
      "f1 score:  0.2222222222222222\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 15: #####\n",
      "\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 16: #####\n",
      "the local fire and ambulance service arrived and removed emp\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 17: #####\n",
      "the wall was too heavy for one person and when it bumped up against a ceiling pipe while being raised he lost control of it\n",
      "f1 score:  0.07142857142857142\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 18: #####\n",
      "the entire east side caved in and buried ed\n",
      "f1 score:  0.823529411764706\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 19: #####\n",
      "municipal tie - in point\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 20: #####\n",
      "the barge capsized employee # 1 was caught in the hopper section trapping him under the barge and he drowned\n",
      "f1 score:  0.2222222222222222\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 21: #####\n",
      "employee # 1 sank and drowned\n",
      "f1 score:  0.6666666666666666\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 22: #####\n",
      "a rain storm flooded the pipe drowning employee # 1\n",
      "f1 score:  0.6\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 23: #####\n",
      "drowned\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 24: #####\n",
      "drowned\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "0.38483470516411694  moyenne de F1 - Score\n",
      "16.0 % moyenne de Exact Match - Score\n"
     ]
    }
   ],
   "source": [
    "s = 0\n",
    "f=0\n",
    "exM=0\n",
    "#\"What was happening after what occured in the place where was it done?\"\n",
    "#\"What was happening at the end?\" 38%\n",
    "#\"What the most thing that was happening and marking the story  at the end?\"  31%\n",
    "# \"What the most thing that was happening and marking the story?\" 31%\n",
    "#\"What the most thing that was happening  in the story?\" 31%\n",
    "#\"What the most thing that was happening?\" 43.83 (the most > 43.27)\n",
    "# \"What is the most controversial thing that happened?\" (46%)\n",
    "# \"What is the worst and risky thing happening?\" 47.88%\n",
    "#\"What is the  most astonishing thing happening?\"  head_only  (41%  16%) |  (head + tail) 50.61%   24%  | 54.61%  28% (head + tail + head_4 + tail_4)\n",
    "for i in range(len(data)):\n",
    "  text_data = data[i]['text']\n",
    "  ground_truth = data[i][\"EVENT\"]\n",
    "  question,text = \"What was happening at the end?\",text_data\n",
    "\n",
    "\n",
    "  text_essay = text[256:256+512]\n",
    "  chunk_size = 512\n",
    "  head_only = text[:chunk_size]\n",
    "  head = text[:chunk_size//2]\n",
    "  tail = text[-chunk_size//2:]\n",
    "\n",
    "  head_2 = text[chunk_size:chunk_size+ 513]\n",
    "  tail_2 = text[chunk_size + 512: chunk_size + 1024]\n",
    "\n",
    "  head_3 = text[chunk_size + 1024: chunk_size + 1536]\n",
    "  tail_3 = text[chunk_size + 1536: chunk_size + 2048]\n",
    "\n",
    "  head_4 = text[chunk_size + 2048: chunk_size + 256]\n",
    "  tail_4 = text[chunk_size + 2560: chunk_size + 3071]\n",
    "\n",
    "  tail_only = text[-chunk_size:]\n",
    "  inputs = tokenizer(question, head + tail, return_tensors=\"pt\")\n",
    "  with torch.no_grad():\n",
    "      outputs = model(**inputs)\n",
    "\n",
    "  answer_start_index = outputs.start_logits.argmax()\n",
    "  answer_end_index = outputs.end_logits.argmax()\n",
    "\n",
    "  predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "  prediction = tokenizer.decode(predict_answer_tokens, skip_special_tokens=True)\n",
    "\n",
    "  When_part = data[i][\"EVENT\"]\n",
    "  f1_score = evaluate_f1(ground_truth, prediction)\n",
    "  f+=f1_score\n",
    "  exact_match = evaluate_exact_match(ground_truth, prediction)\n",
    "  exM += int(exact_match)\n",
    "  print(\"##### example {}: #####\".format(i))\n",
    "  print(prediction)\n",
    "  print(\"f1 score: \",f1_score)\n",
    "  print(\"exact_match: \",int(exact_match),\"\\n\")\n",
    "  print(\"#########\\n\")\n",
    "\n",
    "print(\"{}  moyenne de F1 - Score\".format(f/25))\n",
    "print(\"{} % moyenne de Exact Match - Score\".format((exM/25)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ei9dNwpMSE4g"
   },
   "source": [
    "Pour connaitre le nombre d'exmples dépassant les 512 et inversement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MO3-XC4n7kbd",
    "outputId": "efc54647-ad8e-41c2-be90-cfdb4e6c9e03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exemple 0 de longueur  4002\n",
      "exemple 1 de longueur  2234\n",
      "exemple 2 de longueur  387\n",
      "exemple 3 de longueur  469\n",
      "exemple 4 de longueur  1008\n",
      "exemple 5 de longueur  465\n",
      "exemple 6 de longueur  319\n",
      "exemple 7 de longueur  1088\n",
      "exemple 8 de longueur  1234\n",
      "exemple 9 de longueur  545\n",
      "exemple 10 de longueur  1291\n",
      "exemple 11 de longueur  1020\n",
      "exemple 12 de longueur  786\n",
      "exemple 13 de longueur  853\n",
      "exemple 14 de longueur  464\n",
      "exemple 15 de longueur  764\n",
      "exemple 16 de longueur  537\n",
      "exemple 17 de longueur  390\n",
      "exemple 18 de longueur  536\n",
      "exemple 19 de longueur  1312\n",
      "exemple 20 de longueur  1461\n",
      "exemple 21 de longueur  625\n",
      "exemple 22 de longueur  232\n",
      "exemple 23 de longueur  238\n",
      "exemple 24 de longueur  81\n",
      "9\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "compte_inferieur_512 = 0\n",
    "compte_superieur_512 = 0\n",
    "for i in range(len(data)):\n",
    "  print(\"exemple {} de longueur  {}\".format(i,len(data[i]['text'])))\n",
    "  if len(data[i]['text']) < 512:\n",
    "    compte_inferieur_512+=1\n",
    "compte_superieur_512 = len(data) - compte_inferieur_512\n",
    "print(compte_inferieur_512)\n",
    "print(compte_superieur_512)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GC_Dg9YHEPzz"
   },
   "source": [
    "**when**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LeLnX0PUwky_",
    "outputId": "289175b4-6c44-4380-90fe-8d3a01d2d1f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### example 0: #####\n",
      "november 10 2013\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 1: #####\n",
      "august 27 2012\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 2: #####\n",
      "september 19 2012\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 3: #####\n",
      "november17 2010\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 4: #####\n",
      "september 26 2013\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 5: #####\n",
      "june 14 2011\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 6: #####\n",
      "february 3 2011\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 7: #####\n",
      "february 6 2009\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 8: #####\n",
      "september 29 2011\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 9: #####\n",
      "september 30 2008\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 10: #####\n",
      "august 24 2003\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 11: #####\n",
      "october 24 2008\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 12: #####\n",
      "august 9 2007\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 13: #####\n",
      "june 21 2011\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 14: #####\n",
      "may 21 2009\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 15: #####\n",
      "november 9 2010\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 16: #####\n",
      "november 6 2009\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 17: #####\n",
      "employee # 1 an independent contractor at a construction site\n",
      "f1 score:  0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 18: #####\n",
      "july 12 2007\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 19: #####\n",
      "june 17 2010\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 20: #####\n",
      "april 18 2007\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 21: #####\n",
      "march 26 2012\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 22: #####\n",
      "august 18 2009\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 23: #####\n",
      "september 12 2006\n",
      "f1 score:  1.0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 24: #####\n",
      "what was the date of the event?\n",
      "f1 score:  0\n",
      "exact_match:  1 \n",
      "\n",
      "#########\n",
      "\n",
      "number correct WHEN :0\n",
      "0.0 % correct answers\n",
      "0.92  moyenne de F1 - Score\n",
      "100.0 % moyenne de Exact Match - Score\n"
     ]
    }
   ],
   "source": [
    "s = 0\n",
    "f=0\n",
    "exM=0\n",
    "for i in range(len(data)):\n",
    "  text_data = data[i]['text']\n",
    "  ground_truth = data[i][\"WHEN\"]\n",
    "  question,text = \"What was the date of the event?\",text_data\n",
    "\n",
    "  chunk_size = 512\n",
    "  head = text[:chunk_size//2]\n",
    "  tail = text[-chunk_size//2:]\n",
    "  inputs = tokenizer(question, head + tail, return_tensors=\"pt\")\n",
    "  with torch.no_grad():\n",
    "      outputs = model(**inputs)\n",
    "\n",
    "  answer_start_index = outputs.start_logits.argmax()\n",
    "  answer_end_index = outputs.end_logits.argmax()\n",
    "\n",
    "  predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "  prediction = tokenizer.decode(predict_answer_tokens, skip_special_tokens=True)\n",
    "\n",
    "  When_part = data[i][\"WHEN\"]\n",
    "  f1_score = evaluate_f1(ground_truth, prediction)\n",
    "  f+=f1_score\n",
    "  exM+=int(exact_match)\n",
    "  print(\"##### example {}: #####\".format(i))\n",
    "  print(prediction)\n",
    "  print(\"f1 score: \",f1_score)\n",
    "  print(\"exact_match: \",int(exact_match),\"\\n\")\n",
    "  print(\"#########\\n\")\n",
    "  if prediction == When_part.lower():\n",
    "    s+=1\n",
    "percenantage = (s/25)*100\n",
    "print(\"number correct WHEN :{}\".format(s))\n",
    "print(\"{} % correct answers\".format(percenantage))\n",
    "print(\"{}  moyenne de F1 - Score\".format(f/25))\n",
    "print(\"{} % moyenne de Exact Match - Score\".format((exM/25)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RfnBN8zXwoN0",
    "outputId": "4f30422c-b04d-409a-e4bb-dc3479949c0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Example 0: #####\n",
      "Prediction: november 10 2013\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 1: #####\n",
      "Prediction: august 27 2012\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 2: #####\n",
      "Prediction: september 19 2012\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 3: #####\n",
      "Prediction: 9 : 30 a. m. on november17 2010\n",
      "F1 score: 0.5\n",
      "Exact Match: 0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 4: #####\n",
      "Prediction: september 26 2013\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 5: #####\n",
      "Prediction: june 14 2011\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 6: #####\n",
      "Prediction: february 3 2011\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 7: #####\n",
      "Prediction: february 6 2009\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 8: #####\n",
      "Prediction: september 29 2011\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 9: #####\n",
      "Prediction: september 30 2008\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 10: #####\n",
      "Prediction: august 24 2003\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 11: #####\n",
      "Prediction: october 24 2008\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 12: #####\n",
      "Prediction: august 9 2007\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 13: #####\n",
      "Prediction: june 21 2011\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 14: #####\n",
      "Prediction: may 21 2009\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 15: #####\n",
      "Prediction: november 9 2010\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 16: #####\n",
      "Prediction: november 6 2009\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 17: #####\n",
      "Prediction: construction site\n",
      "F1 score: 0\n",
      "Exact Match: 0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 18: #####\n",
      "Prediction: july 12 2007\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 19: #####\n",
      "Prediction: june 17 2010\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 20: #####\n",
      "Prediction: april 18 2007\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 21: #####\n",
      "Prediction: march 26 2012\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 22: #####\n",
      "Prediction: august 18 2009\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 23: #####\n",
      "Prediction: september 12 2006\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 24: #####\n",
      "Prediction: diver\n",
      "F1 score: 0\n",
      "Exact Match: 0 \n",
      "\n",
      "#########\n",
      "\n",
      "Number correct EVENT: 0\n",
      "0.00% correct answers\n",
      "0.90 Average F1 Score\n",
      "88.00% Average Exact Match Score\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "window_size = 512  # Max tokens per window\n",
    "stride = 128  # Overlap size\n",
    "\n",
    "# Split text into overlapping windows\n",
    "def sliding_windows(text, window_size, stride):\n",
    "    input_ids = tokenizer.encode(text, add_special_tokens=False)\n",
    "    windows = []\n",
    "    for i in range(0, len(input_ids), stride):\n",
    "        window = input_ids[i:i + window_size]\n",
    "        windows.append(window)\n",
    "    return windows\n",
    "\n",
    "# Initialize scores\n",
    "s = 0\n",
    "f = 0\n",
    "exM = 0\n",
    "\n",
    "for i in range(len(data)):\n",
    "    text_data = data[i]['text']\n",
    "    ground_truth = data[i][\"WHEN\"]\n",
    "    question, text = \"When was the employee doing staff?\", text_data\n",
    "\n",
    "    windows = sliding_windows(text_data, window_size, stride)\n",
    "    answers = []\n",
    "\n",
    "    # Get answers from each window\n",
    "    for window in windows:\n",
    "        tokens = tokenizer.convert_ids_to_tokens(window, skip_special_tokens=True)\n",
    "        window_text = tokenizer.convert_tokens_to_string(tokens)\n",
    "\n",
    "        inputs = tokenizer.encode_plus(question, window_text, return_tensors=\"pt\", truncation=True, max_length=window_size)\n",
    "        input_ids = inputs[\"input_ids\"]\n",
    "        attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        start_scores = outputs.start_logits\n",
    "        end_scores = outputs.end_logits\n",
    "        all_tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "\n",
    "        # Get the best answer within this window\n",
    "        answer_start = torch.argmax(start_scores)\n",
    "        answer_end = torch.argmax(end_scores) + 1\n",
    "\n",
    "        if answer_start < answer_end and answer_end <= len(all_tokens):\n",
    "            answer = tokenizer.convert_tokens_to_string(all_tokens[answer_start:answer_end])\n",
    "            score = start_scores[0][answer_start] + end_scores[0][answer_end - 1]\n",
    "            answers.append((answer, score.item()))\n",
    "\n",
    "    # Select the best answer based on score\n",
    "    prediction = max(answers, key=lambda x: x[1])[0] if answers else \"No answer found\"\n",
    "\n",
    "    # Evaluate performance\n",
    "    f1_score = evaluate_f1(ground_truth, prediction)\n",
    "    f += f1_score\n",
    "    exact_match = evaluate_exact_match(ground_truth, prediction)\n",
    "    exM += int(exact_match)\n",
    "\n",
    "    print(f\"##### Example {i}: #####\")\n",
    "    print(\"Prediction:\", prediction)\n",
    "    print(\"F1 score:\", f1_score)\n",
    "    print(\"Exact Match:\", int(exact_match), \"\\n\")\n",
    "    print(\"#########\\n\")\n",
    "\n",
    "    if prediction.lower() == ground_truth.lower():\n",
    "        s += 1\n",
    "\n",
    "# Final Metrics\n",
    "percentage = (s / len(data)) * 100\n",
    "print(f\"Number correct EVENT: {s}\")\n",
    "print(f\"{percentage:.2f}% correct answers\")\n",
    "print(f\"{f / len(data):.2f} Average F1 Score\")\n",
    "print(f\"{(exM / len(data)) * 100:.2f}% Average Exact Match Score\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8GAmIu3VEjge",
    "outputId": "51074138-5d12-4055-8e6c-d59ac8f42fc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### example 0: #####\n",
      "november 10 2013\n",
      "f1 score:  1.0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 1: #####\n",
      "august 27 2012\n",
      "f1 score:  1.0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 2: #####\n",
      "september 19 2012\n",
      "f1 score:  1.0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 3: #####\n",
      "november17 2010\n",
      "f1 score:  1.0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 4: #####\n",
      "september 26 2013\n",
      "f1 score:  1.0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 5: #####\n",
      "june 14 2011\n",
      "f1 score:  1.0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 6: #####\n",
      "february 3 2011\n",
      "f1 score:  1.0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 7: #####\n",
      "february 6 2009\n",
      "f1 score:  1.0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 8: #####\n",
      "september 29 2011\n",
      "f1 score:  1.0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 9: #####\n",
      "september 30 2008\n",
      "f1 score:  1.0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 10: #####\n",
      "august 24 2003\n",
      "f1 score:  1.0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 11: #####\n",
      "october 24 2008\n",
      "f1 score:  1.0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 12: #####\n",
      "august 9 2007\n",
      "f1 score:  1.0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 13: #####\n",
      "june 21 2011\n",
      "f1 score:  1.0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 14: #####\n",
      "may 21 2009\n",
      "f1 score:  1.0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 15: #####\n",
      "november 9 2010\n",
      "f1 score:  1.0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 16: #####\n",
      "november 6 2009\n",
      "f1 score:  1.0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 17: #####\n",
      "construction site\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 18: #####\n",
      "july 12 2007\n",
      "f1 score:  1.0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 19: #####\n",
      "june 17 2010\n",
      "f1 score:  1.0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 20: #####\n",
      "april 18 2007\n",
      "f1 score:  1.0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 21: #####\n",
      "march 26 2012\n",
      "f1 score:  1.0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 22: #####\n",
      "august 18 2009\n",
      "f1 score:  1.0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 23: #####\n",
      "september 12 2006\n",
      "f1 score:  1.0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### example 24: #####\n",
      "diver\n",
      "f1 score:  0\n",
      "exact_match:  0 \n",
      "\n",
      "#########\n",
      "\n",
      "0.92  moyenne de F1 - Score\n",
      "0.0 % moyenne de Exact Match - Score\n"
     ]
    }
   ],
   "source": [
    "\n",
    "f=0\n",
    "exM=0\n",
    "for i in range(len(data)):\n",
    "  text_data = data[i]['text']\n",
    "  ground_truth = data[i][\"WHEN\"]\n",
    "  question,text = \"When was the employee doing staff?\",text_data\n",
    "\n",
    "  chunk_size = 512\n",
    "  head = text[:chunk_size//2]\n",
    "  tail = text[-chunk_size//2:]\n",
    "  inputs = tokenizer(question, head + tail, return_tensors=\"pt\")\n",
    "  with torch.no_grad():\n",
    "      outputs = model(**inputs)\n",
    "\n",
    "  answer_start_index = outputs.start_logits.argmax()\n",
    "  answer_end_index = outputs.end_logits.argmax()\n",
    "\n",
    "  predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "  prediction = tokenizer.decode(predict_answer_tokens, skip_special_tokens=True)\n",
    "\n",
    "  When_part = data[i][\"WHEN\"]\n",
    "  f1_score = evaluate_f1(ground_truth, prediction)\n",
    "  f+=f1_score\n",
    "  exM+=int(exM)\n",
    "  print(\"##### example {}: #####\".format(i))\n",
    "  print(prediction)\n",
    "  print(\"f1 score: \",f1_score)\n",
    "  print(\"exact_match: \",int(exM),\"\\n\")\n",
    "  print(\"#########\\n\")\n",
    "\n",
    "print(\"{}  moyenne de F1 - Score\".format(f/25))\n",
    "print(\"{} % moyenne de Exact Match - Score\".format((exM/25)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dgBZUPwPwpRY",
    "outputId": "c3ea03d7-dba3-48f3-9c35-58beee3f1011"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Example 0: #####\n",
      "Prediction: november 10 2013\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 1: #####\n",
      "Prediction: august 27 2012 employee # 1 a 19 year - old male laborer with stomper company inc. arrived at 2 : 00. am. at a site in menlo park california to demolish the interiors of the building. they scraped the interiors of the building and collected debris as they finished up the job. on august 28 2012\n",
      "F1 score: 0.12\n",
      "Exact Match: 0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 2: #####\n",
      "Prediction: september 19 2012\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 3: #####\n",
      "Prediction: november17 2010\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 4: #####\n",
      "Prediction: september 26 2013\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 5: #####\n",
      "Prediction: june 14 2011\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 6: #####\n",
      "Prediction: february 3 2011\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 7: #####\n",
      "Prediction: february 6 2009\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 8: #####\n",
      "Prediction: september 29 2011\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 9: #####\n",
      "Prediction: september 30 2008\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 10: #####\n",
      "Prediction: august 24 2003\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 11: #####\n",
      "Prediction: october 24 2008\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 12: #####\n",
      "Prediction: august 9 2007\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 13: #####\n",
      "Prediction: june 21 2011\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 14: #####\n",
      "Prediction: may 21 2009\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 15: #####\n",
      "Prediction: november 9 2010\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 16: #####\n",
      "Prediction: november 6 2009\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 17: #####\n",
      "Prediction: \n",
      "F1 score: 1\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 18: #####\n",
      "Prediction: july 12 2007\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 19: #####\n",
      "Prediction: june 17 2010\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 20: #####\n",
      "Prediction: april 18 2007\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 21: #####\n",
      "Prediction: march 26 2012\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 22: #####\n",
      "Prediction: august 18 2009\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 23: #####\n",
      "Prediction: september 12 2006\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 24: #####\n",
      "Prediction: drowned.\n",
      "F1 score: 0\n",
      "Exact Match: 0 \n",
      "\n",
      "#########\n",
      "\n",
      "Number correct EVENT: 1\n",
      "4.00% correct answers\n",
      "0.92 Average F1 Score\n",
      "92.00% Average Exact Match Score\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "window_size = 512  # Max tokens per window\n",
    "stride = 128  # Overlap size\n",
    "\n",
    "# Split text into overlapping windows\n",
    "def sliding_windows(text, window_size, stride):\n",
    "    input_ids = tokenizer.encode(text, add_special_tokens=False)\n",
    "    windows = []\n",
    "    for i in range(0, len(input_ids), stride):\n",
    "        window = input_ids[i:i + window_size]\n",
    "        windows.append(window)\n",
    "    return windows\n",
    "\n",
    "# Initialize scores\n",
    "s = 0\n",
    "f = 0\n",
    "exM = 0\n",
    "\n",
    "for i in range(len(data)):\n",
    "    text_data = data[i]['text']\n",
    "    ground_truth = data[i][\"WHEN\"]\n",
    "    question, text = \"What was the date of the event?\", text_data\n",
    "\n",
    "    windows = sliding_windows(text_data, window_size, stride)\n",
    "    answers = []\n",
    "\n",
    "    # Get answers from each window\n",
    "    for window in windows:\n",
    "        tokens = tokenizer.convert_ids_to_tokens(window, skip_special_tokens=True)\n",
    "        window_text = tokenizer.convert_tokens_to_string(tokens)\n",
    "\n",
    "        inputs = tokenizer.encode_plus(question, window_text, return_tensors=\"pt\", truncation=True, max_length=window_size)\n",
    "        input_ids = inputs[\"input_ids\"]\n",
    "        attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        start_scores = outputs.start_logits\n",
    "        end_scores = outputs.end_logits\n",
    "        all_tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "\n",
    "        # Get the best answer within this window\n",
    "        answer_start = torch.argmax(start_scores)\n",
    "        answer_end = torch.argmax(end_scores) + 1\n",
    "\n",
    "        if answer_start < answer_end and answer_end <= len(all_tokens):\n",
    "            answer = tokenizer.convert_tokens_to_string(all_tokens[answer_start:answer_end])\n",
    "            score = start_scores[0][answer_start] + end_scores[0][answer_end - 1]\n",
    "            answers.append((answer, score.item()))\n",
    "\n",
    "    # Select the best answer based on score\n",
    "    prediction = max(answers, key=lambda x: x[1])[0] if answers else \"\"\n",
    "\n",
    "    # Evaluate performance\n",
    "    f1_score = evaluate_f1(ground_truth, prediction)\n",
    "    f += f1_score\n",
    "    exact_match = evaluate_exact_match(ground_truth, prediction)\n",
    "    exM += int(exact_match)\n",
    "\n",
    "    print(f\"##### Example {i}: #####\")\n",
    "    print(\"Prediction:\", prediction)\n",
    "    print(\"F1 score:\", f1_score)\n",
    "    print(\"Exact Match:\", int(exact_match), \"\\n\")\n",
    "    print(\"#########\\n\")\n",
    "\n",
    "    if prediction.lower() == ground_truth.lower():\n",
    "        s += 1\n",
    "\n",
    "# Final Metrics\n",
    "percentage = (s / len(data)) * 100\n",
    "print(f\"Number correct EVENT: {s}\")\n",
    "print(f\"{percentage:.2f}% correct answers\")\n",
    "print(f\"{f / len(data):.2f} Average F1 Score\")\n",
    "print(f\"{(exM / len(data)) * 100:.2f}% Average Exact Match Score\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Iw20P6Qxw5mw",
    "outputId": "4fd0df1d-d297-4385-b731-48225f7f5816"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Example 0: #####\n",
      "Prediction: november 10 2013\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 1: #####\n",
      "Prediction: august 27 2012\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 2: #####\n",
      "Prediction: september 19 2012\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 3: #####\n",
      "Prediction: november17 2010\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 4: #####\n",
      "Prediction: september 26 2013\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 5: #####\n",
      "Prediction: june 14 2011\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 6: #####\n",
      "Prediction: february 3 2011\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 7: #####\n",
      "Prediction: february 6 2009\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 8: #####\n",
      "Prediction: september 29 2011\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 9: #####\n",
      "Prediction: september 30 2008\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 10: #####\n",
      "Prediction: august 24 2003\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 11: #####\n",
      "Prediction: october 24 2008\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 12: #####\n",
      "Prediction: august 9 2007\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 13: #####\n",
      "Prediction: june 21 2011\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 14: #####\n",
      "Prediction: may 21 2009\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 15: #####\n",
      "Prediction: november 9 2010\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 16: #####\n",
      "Prediction: november 6 2009\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 17: #####\n",
      "Prediction: \n",
      "F1 score: 1\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 18: #####\n",
      "Prediction: july 12 2007\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 19: #####\n",
      "Prediction: june 17 2010\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 20: #####\n",
      "Prediction: april 18 2007\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 21: #####\n",
      "Prediction: march 26 2012\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 22: #####\n",
      "Prediction: august 18 2009\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 23: #####\n",
      "Prediction: september 12 2006\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 24: #####\n",
      "Prediction: drowned\n",
      "F1 score: 0\n",
      "Exact Match: 0 \n",
      "\n",
      "#########\n",
      "\n",
      "Number correct EVENT: 1\n",
      "4.00% correct answers\n",
      "0.96 Average F1 Score\n",
      "96.00% Average Exact Match Score\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "window_size = 512  # Max tokens per window\n",
    "stride = 128  # Overlap size\n",
    "\n",
    "# Split text into overlapping windows\n",
    "def sliding_windows(text, window_size, stride):\n",
    "    input_ids = tokenizer.encode(text, add_special_tokens=False)\n",
    "    windows = []\n",
    "    for i in range(0, len(input_ids), stride):\n",
    "        window = input_ids[i:i + window_size]\n",
    "        windows.append(window)\n",
    "    return windows\n",
    "\n",
    "# Initialize scores\n",
    "s = 0\n",
    "f = 0\n",
    "exM = 0\n",
    "\n",
    "for i in range(len(data)):\n",
    "    text_data = data[i]['text']\n",
    "    ground_truth = data[i][\"WHEN\"]\n",
    "    question, text = \"What was the exact day?\", text_data\n",
    "\n",
    "    windows = sliding_windows(text_data, window_size, stride)\n",
    "    answers = []\n",
    "\n",
    "    # Get answers from each window\n",
    "    for window in windows:\n",
    "        tokens = tokenizer.convert_ids_to_tokens(window, skip_special_tokens=True)\n",
    "        window_text = tokenizer.convert_tokens_to_string(tokens)\n",
    "\n",
    "        inputs = tokenizer.encode_plus(question, window_text, return_tensors=\"pt\", truncation=True, max_length=window_size)\n",
    "        input_ids = inputs[\"input_ids\"]\n",
    "        attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        start_scores = outputs.start_logits\n",
    "        end_scores = outputs.end_logits\n",
    "        all_tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "\n",
    "        # Get the best answer within this window\n",
    "        answer_start = torch.argmax(start_scores)\n",
    "        answer_end = torch.argmax(end_scores) + 1\n",
    "\n",
    "        if answer_start < answer_end and answer_end <= len(all_tokens):\n",
    "            answer = tokenizer.convert_tokens_to_string(all_tokens[answer_start:answer_end])\n",
    "            score = start_scores[0][answer_start] + end_scores[0][answer_end - 1]\n",
    "            answers.append((answer, score.item()))\n",
    "\n",
    "    # Select the best answer based on score\n",
    "    prediction = max(answers, key=lambda x: x[1])[0] if answers else \"\"\n",
    "\n",
    "    # Evaluate performance\n",
    "    f1_score = evaluate_f1(ground_truth, prediction)\n",
    "    f += f1_score\n",
    "    exact_match = evaluate_exact_match(ground_truth, prediction)\n",
    "    exM += int(exact_match)\n",
    "\n",
    "    print(f\"##### Example {i}: #####\")\n",
    "    print(\"Prediction:\", prediction)\n",
    "    print(\"F1 score:\", f1_score)\n",
    "    print(\"Exact Match:\", int(exact_match), \"\\n\")\n",
    "    print(\"#########\\n\")\n",
    "\n",
    "    if prediction.lower() == ground_truth.lower():\n",
    "        s += 1\n",
    "\n",
    "# Final Metrics\n",
    "percentage = (s / len(data)) * 100\n",
    "print(f\"Number correct EVENT: {s}\")\n",
    "print(f\"{percentage:.2f}% correct answers\")\n",
    "print(f\"{f / len(data):.2f} Average F1 Score\")\n",
    "print(f\"{(exM / len(data)) * 100:.2f}% Average Exact Match Score\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tRCk4jCaxDc5",
    "outputId": "40d2d6d9-72b5-4809-8de8-f6f8d3271568"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Example 0: #####\n",
      "Prediction: november 10 2013\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 1: #####\n",
      "Prediction: august 27 2012 employee # 1 a 19 year - old male laborer with stomper company inc. arrived at 2 : 00. am. at a site in menlo park california to demolish the interiors of the building. they scraped the interiors of the building and collected debris as they finished up the job. on august 28 2012\n",
      "F1 score: 0.12\n",
      "Exact Match: 0 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 2: #####\n",
      "Prediction: september 19 2012\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 3: #####\n",
      "Prediction: november17 2010\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 4: #####\n",
      "Prediction: september 26 2013\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 5: #####\n",
      "Prediction: june 14 2011\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 6: #####\n",
      "Prediction: february 3 2011\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 7: #####\n",
      "Prediction: february 6 2009\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 8: #####\n",
      "Prediction: september 29 2011\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 9: #####\n",
      "Prediction: september 30 2008\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 10: #####\n",
      "Prediction: august 24 2003\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 11: #####\n",
      "Prediction: october 24 2008\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 12: #####\n",
      "Prediction: august 9 2007\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 13: #####\n",
      "Prediction: june 21 2011\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 14: #####\n",
      "Prediction: may 21 2009\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 15: #####\n",
      "Prediction: november 9 2010\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 16: #####\n",
      "Prediction: november 6 2009\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 17: #####\n",
      "Prediction: \n",
      "F1 score: 1\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 18: #####\n",
      "Prediction: july 12 2007\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 19: #####\n",
      "Prediction: june 17 2010\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 20: #####\n",
      "Prediction: april 18 2007\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 21: #####\n",
      "Prediction: march 26 2012\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 22: #####\n",
      "Prediction: august 18 2009\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 23: #####\n",
      "Prediction: september 12 2006\n",
      "F1 score: 1.0\n",
      "Exact Match: 1 \n",
      "\n",
      "#########\n",
      "\n",
      "##### Example 24: #####\n",
      "Prediction: drowned.\n",
      "F1 score: 0\n",
      "Exact Match: 0 \n",
      "\n",
      "#########\n",
      "\n",
      "Number correct EVENT: 1\n",
      "4.00% correct answers\n",
      "0.92 Average F1 Score\n",
      "92.00% Average Exact Match Score\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "window_size = 512  # Max tokens per window\n",
    "stride = 128  # Overlap size\n",
    "\n",
    "# Split text into overlapping windows\n",
    "def sliding_windows(text, window_size, stride):\n",
    "    input_ids = tokenizer.encode(text, add_special_tokens=False)\n",
    "    windows = []\n",
    "    for i in range(0, len(input_ids), stride):\n",
    "        window = input_ids[i:i + window_size]\n",
    "        windows.append(window)\n",
    "    return windows\n",
    "\n",
    "# Initialize scores\n",
    "s = 0\n",
    "f = 0\n",
    "exM = 0\n",
    "\n",
    "for i in range(len(data)):\n",
    "    text_data = data[i]['text']\n",
    "    ground_truth = data[i][\"WHEN\"]\n",
    "    question, text = \"What was the date of the event?\", text_data\n",
    "\n",
    "    windows = sliding_windows(text_data, window_size, stride)\n",
    "    answers = []\n",
    "\n",
    "    # Get answers from each window\n",
    "    for window in windows:\n",
    "        tokens = tokenizer.convert_ids_to_tokens(window, skip_special_tokens=True)\n",
    "        window_text = tokenizer.convert_tokens_to_string(tokens)\n",
    "\n",
    "        inputs = tokenizer.encode_plus(question, window_text, return_tensors=\"pt\", truncation=True, max_length=window_size)\n",
    "        input_ids = inputs[\"input_ids\"]\n",
    "        attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        start_scores = outputs.start_logits\n",
    "        end_scores = outputs.end_logits\n",
    "        all_tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "\n",
    "        # Get the best answer within this window\n",
    "        answer_start = torch.argmax(start_scores)\n",
    "        answer_end = torch.argmax(end_scores) + 1\n",
    "\n",
    "        if answer_start < answer_end and answer_end <= len(all_tokens):\n",
    "            answer = tokenizer.convert_tokens_to_string(all_tokens[answer_start:answer_end])\n",
    "            score = start_scores[0][answer_start] + end_scores[0][answer_end - 1]\n",
    "            answers.append((answer, score.item()))\n",
    "\n",
    "    # Select the best answer based on score\n",
    "    prediction = max(answers, key=lambda x: x[1])[0] if answers else \"\"\n",
    "\n",
    "    # Evaluate performance\n",
    "    f1_score = evaluate_f1(ground_truth, prediction)\n",
    "    f += f1_score\n",
    "    exact_match = evaluate_exact_match(ground_truth, prediction)\n",
    "    exM += int(exact_match)\n",
    "\n",
    "    print(f\"##### Example {i}: #####\")\n",
    "    print(\"Prediction:\", prediction)\n",
    "    print(\"F1 score:\", f1_score)\n",
    "    print(\"Exact Match:\", int(exact_match), \"\\n\")\n",
    "    print(\"#########\\n\")\n",
    "\n",
    "    if prediction.lower() == ground_truth.lower():\n",
    "        s += 1\n",
    "\n",
    "# Final Metrics\n",
    "percentage = (s / len(data)) * 100\n",
    "print(f\"Number correct EVENT: {s}\")\n",
    "print(f\"{percentage:.2f}% correct answers\")\n",
    "print(f\"{f / len(data):.2f} Average F1 Score\")\n",
    "print(f\"{(exM / len(data)) * 100:.2f}% Average Exact Match Score\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMOSz6pXaL7r"
   },
   "source": [
    "On remarque qu’il y a 6 exemples ou la taille correspond à celle par défaut pour la fenetre de Bert (<512) et les autres 16 exemples dépassent jusqu’à atteindre taille de 4002.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d5eCLKvraxHh"
   },
   "source": [
    "Donc , on a abordé les stratégies de sliding window et la concaténation de différents parties afin de résoudre ce problème et on a fait les comparaisons principalement entre la méthode par défaut et celle de la concaténation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r5PdWLR_jDua"
   },
   "source": [
    "# 1 .Les réultats pour les 3 informations :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WCHnq2BejGeM"
   },
   "source": [
    "On s’intéresse dans notre analyse à la mesure de F1 Score plus que Exact match  (puisque elle permet de vérifier la capacité de notre modèle à trouver le contexte proche de la réponse en partie ou en tout ) car si on trouve une partie importante de la réponse pour chaque exemple le F1 Score va etre élevée et donc une bonne performance alors que Exact match est plutôt stricte puisqu’il faut que la prédiction est exacte à la réponse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCVNv7u7jInq"
   },
   "source": [
    "......"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Of0yP9P4jV1t"
   },
   "source": [
    "WHEN :      F1 Score : 96%    Exact match : 96%  \n",
    "        \n",
    "> => La valeur de F1 Score est très bon ( 90%< 96%<= 100%) . On a pu repérer 24/25  mots exactement correct.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYBVaONnjtVf"
   },
   "source": [
    "WHERE :      F1 Score : 74.33%    Exact match : 64%\n",
    "\n",
    "> =>\tLa valeur de F1 Score est moyen (puisque  50% < 74.33% < 80%)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HVjnF_jajvFv"
   },
   "source": [
    "EVENT :      F1 Score :  54.62%    Exact match : 28%\n",
    "\n",
    "> =>\tLa valeur de F1 Score est moyen (puisque  50% < 54.62%< 80%)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uzF5aWFYkg3o"
   },
   "source": [
    "**Conclusion : Le modèle a pu bien repérer les réponses pour le WHEN  , moyennement le WHERE et moins bon l’EVENT .**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9aeuqdesknbY"
   },
   "source": [
    "# 2. Analyse de choix de partie :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "372YXYBAkzq3"
   },
   "source": [
    "WHEN :  situé au début"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTRbD-R9k1bR"
   },
   "source": [
    "WHERE : situé au début et au milieu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JlNkZ1WIk1yy"
   },
   "source": [
    "EVENT : situé au début et à la fin surtout.  (il est aussi éparpillé dans toute la phrase et plusieurs autres choses (événements , situations ) qui se passent proches dans le sens et position dans les phrases (cela peut causer des erreurs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MFM78hzalCN4"
   },
   "source": [
    "# 3.Discussion du choix de question : (Performance et explication globale de don choix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZiUxkHRJlDqL"
   },
   "source": [
    "**WHEN :**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q6Cz77tpo216"
   },
   "source": [
    "1er partie :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m_EvAcuQpBzh"
   },
   "source": [
    "On a utilisé la technique de fenetre glissante pour taille fenetre = taille maximale que le model Bert peut prendre comme fenetre et le stride (pas pour la fenetre) est 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m4OeKQK2pEko"
   },
   "source": [
    "« When was the employee doing staff? »  F1 Score 90% Exact Match  88%    (sliding window)  | (les premiers 256 et les derniers 256 tokens )   F1 Score 92% Exact Match  0%\n",
    "\n",
    "> =>\tOn a choisi  When pour repérer la date et on a remarqué que le contexte du temps est liée dans la plupart des cas à l’employé (Employee) .\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bp5hxxDWpPKg"
   },
   "source": [
    "« What was the date of the event? » F1 Score 92% Exact Match  92%  (sliding window)\n",
    "\n",
    "> =>\tCette question s’intéresse a la date étant liée au contexte d’un événement qui se passe .\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lySH6Bo_pY7Y"
   },
   "source": [
    "« What was the day? » F1 Score 90% Exact Match  84% (sliding window)\n",
    "\n",
    "> =>\tCette question met le focus plus sur la date exacte ce qui permet de mieux repérer les dates .\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GuuFP_IvAb8o"
   },
   "source": [
    "\n",
    "« What was the exact day? » F1 Score 96% Exact Match  96% (sliding window)   | F1 Score 100% Exact Match  0%  (les premiers 256 et les derniers 256 tokens )\n",
    "> => Cette question met le focus plus sur la date exacte ce qui permet de mieux repérer les dates .\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2B8pSHWfpiYy"
   },
   "source": [
    "Conclusion à propos des 3 formulations :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iiHzgchhprFW"
   },
   "source": [
    "Les formulations sont proches en termes  de performance et celle qui donne le plus de contexte meme en cas d’absence de date est la dernière."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QDlOVgM4pt3P"
   },
   "source": [
    "Conclusion à propos de la  comparaison des stratégies:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XG8NBAiMpwdV"
   },
   "source": [
    "On conclut que la  cominaison des tokens des  parties de debut et de fin est légérement meuilleur en termes de F1 score (2% à 4 %) mais ayant un exact match nulle donc on opte pour le sliding window pour la formulation de la question WHEN  « What was the exact day? » F1 Score 96% Exact Match  96%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zg3401BQp4_N"
   },
   "source": [
    "La fenetre glissante dans ce type de question est plus efficace que la methode de choisir une combinaison de parties de la phrase au debut et a la fin pour prendre la partie la plus importante dans le contexte puisque sa performance est meuilleur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x5BmJAzZp9US"
   },
   "source": [
    "**WHERE :**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dkRxtPlEqDhx"
   },
   "source": [
    "\"where was it mostly?\"  F1 Score 59%   Exact Match 44% (test_debut : cad les premiers 512 jetons)\n",
    "> =>\tOn retient que cette formulation donne le lieu qui peut etre comme emplacement qui n’est pas le point d’interet des événements dans plusieurs cas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GCVIfcwYAq3d"
   },
   "source": [
    "\"where was it done?\"   F1 Score 67.56%   Exact Match 44% (head + tail)  | les premiers 512 :  F1 Score 70%   Exact Match 56%  \n",
    "\n",
    "> => On a choisi ce type de question   pour avoir un lieu comme dans la 1ère  formulation qui n’est pas nécessairement dans ce contexte de « mostly » cad on ne l’a pas restrient à certains lieux ce qui a permis de correspondre mieux aux exemples.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MWoiooVvA1pl"
   },
   "source": [
    "\"Where was the actual place it was occuring?\"  F1 Score 74.33%   Exact Match  (text_debut + head_3) 64%  | les premiers 512 :  F1 Score 73.1%   Exact Match 64%  \n",
    "\n",
    "> Le choix de cette question est liée au fait qu’un lieu est liée à un événement .\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-TA6tUd0A8si"
   },
   "source": [
    "   Conclusion à propos des 3 formulations :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y-nCUgi7BAKh"
   },
   "source": [
    "On a choisi  WHERE pour trouver le lieu .De plus , on a remarqué que le contexte est le lieu qui marque  quelque chose qui s’est passée (un événement  présent) et non juste un emplacement qui n’a pas subit une situation (comme 2ème formulation) puisque il existe plusieurs possibilités de lieu (d’où le manque de performance du 2ème formulation par rapport à la dernière et la 1ère est proche du 2ème donc la meme chose)  ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dTCT6UMXBFRM"
   },
   "source": [
    "Conclusion à propos de la comparaison des stratégies:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WAbO1wg4BFe1"
   },
   "source": [
    "La combinaison de parties de la phrase au milieu dans ce type de question est plus efficace que la methode de choisir prendre juste la partie par défaut parle transformer de Bert ce qui a permis pour la meuilleur formulation de gagner presque 2% en F1score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDlfJH5MBK3R"
   },
   "source": [
    "**EVENT :**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-Ug1Tn9BP_4"
   },
   "source": [
    "\"What was happening at the end?\" (les premiers 512) F1 Score 30% |(les premiers et les derniers 256 tokens)  F1 Score 38.48%   Exact match16% |42.48%  20% (head + tail + head_4 + tail_4)\n",
    "\n",
    "> =>\tCette question se concentre sur les événements précis et factuels qui se produisent à la fin d’un scenario\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JUCZ26yFBSsh"
   },
   "source": [
    "“What is the most controversial thing that happened?” F1 score 47.21% (head + tail + head_4 + tail_4) Exact match 24%\n",
    "\n",
    "> =>\tCette question cible des événements marquants qui suscitent des divergences d'opinion  ou des conflits.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dG15xpQeBd9h"
   },
   "source": [
    "\"What is the  most astonishing thing happening?\"  head_only  (39.59%  16%) |  (head + tail) 50.61%   24%  | 54.56%  28% (head + tail + head_4 + tail_4)\n",
    "\n",
    "> =>\tl’objectif est d’identifier quelque chose de surprenant ou d’extraordinaire dans le context.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fmdpO8ZMBmhW"
   },
   "source": [
    "comparaison des stratégies:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TrPcVCFFBoAi"
   },
   "source": [
    "Pour la 3ème et la 1ère  formulation en adoptant la technique de concaténation de différents parties (les 1er 256 et les derniers 256 tokens) on a pu ganger par rapport à la startégie par défaut (les premiers 512 tokens)  presque (9 à 10%) en F1 score . Par conséquent la partie de réponse est non pas toujours situés au début et pour mieux s’assurer de cela on a essayé la concaténation du précédente + concaténation des tokens d’un autre emplacement à la fin et on a gagné presque ( 12 à 14%) en F1 score . Cela affirme que une grande partie des exemples contient l’information à la fin.Donc la technique de concaténation est plus efficace que prendre celle par défaut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VpNjImzsBoDG"
   },
   "source": [
    "# 4.Les erreurs dans les types de questions :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zZ9C-Qn2BoF2"
   },
   "source": [
    "**WHEN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o-fyiRkiB_y6"
   },
   "source": [
    "*1ère formulation:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7dcw92czBoIU"
   },
   "source": [
    "Les 2 fautes de la 1ere  (90%) sont dans les 2 exemples (17 et 24) :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rSF-1PtLDMK3"
   },
   "source": [
    " \" Employee #1  a diver  became caught in a coffer dam and drowned.                \" (le dernier exemple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RxCLeZ8GDNV1"
   },
   "source": [
    "\" Employee #1  an independent contractor at a construction site  was trying to  stand on end a wood-framed wall. The wall was too heavy for one person and  when it bumped up against a ceiling pipe while being raised  he lost control  of it. The wall fell on Employee #1  who sustained a compressed disc in his  back.                                                                           \" (ligne 105 du fichier json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KsVKgMkdBoLy"
   },
   "source": [
    "*2ème formulation:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7eNa1JCUCjaS"
   },
   "source": [
    "la faute dans l’exemple 2 qu’il a ajouté en plus de la date , l’horaire de la journée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "321aH0dkCIaw"
   },
   "source": [
    "*3ème formulation* :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDQyXRM4CvbO"
   },
   "source": [
    "les 2 fautes dans les exemples 17 et 24 puisque il a retourné une chaine non vide et aussi elle n’est pas une date ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wNjb0X5LCLu4"
   },
   "source": [
    "*4ème formulation:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_UNE2uwZCLxF"
   },
   "source": [
    "On a bien résolu un des 2 exemples  faux dans la 1ère , ça peut s’expliquer par le fait d’avoir en contexte la date exacte permet de repérer l’exemple ou il  ne figure pas de dates ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3aiohzmCC8I8"
   },
   "source": [
    "\n",
    "\n",
    "> =>\tla plupart des fautes dans les différents est liée à la difficulté de bien repérer l’absence de la réponse (cad chaine vide).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1pL2n_fC4JN"
   },
   "source": [
    "**WHERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BhJOqGrNDBRJ"
   },
   "source": [
    "Les erreurs commis par :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ug0KGsQaCLzf"
   },
   "source": [
    "*1ère formulation:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0yKJsH9sDCjO"
   },
   "source": [
    "les exemples 3 , 4 , 10 , 12, 14 , 15 , 17 ,18 , 20   totalement faux (f1 score = 0 ou presque = 0),  et les exemples partiellement faux (exact_match = 0 et f1_score < 1 ) sont 0 , 7, 8 , 16 ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TDeX1v1nCL1x"
   },
   "source": [
    "*2ème formulation:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S-D0C98UDHE3"
   },
   "source": [
    "les exemples 2 , 3 , 4 , 7, 10 , 15 , 17  , 22  totalement(ou presque totalement)  faux ,  et les exemples partiellement faux (exact_match = 0 et f1_score < 1 ) sont 0 , 5 , 8, 12  , 13 , 14 , 19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dcVqjflYCL4N"
   },
   "source": [
    "*3ème formulation*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jkbEcSfOCL6F"
   },
   "source": [
    "les exemples totalement(ou presque totalement)  faux 3 , 8 , 10 ,12 , 15 et les exemples partiellement faux  sont 16 , 19  et les exemples partiellement faux (exact_match = 0 et f1_score < 1 ) sont 0 , 7, 16 ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFnLI4_lDfgs"
   },
   "source": [
    "\n",
    "\n",
    "> =>\tOn peut conclure qu’il y a des exemples communs qui sont faux dans les différentes formulations , on peut assumer que ces exemples ( 3 , 10 , 15) sont les plus problématiques.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NOlbLo4cDiVF"
   },
   "source": [
    "**EVENT**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Lz9123wDm0O"
   },
   "source": [
    "Les erreurs commis par :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mlnk_m1sCL8d"
   },
   "source": [
    "*1ère formulation:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fehkLoRsDojR"
   },
   "source": [
    "les exemples (presque totalement) faussess sont 1 , 2 ,3 , 4 , 6 , 7 , 8 , 9 , 14 , 17 , 19  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q04LVOuWCMAH"
   },
   "source": [
    "*2ème formulation:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d5k9ncPDDxnr"
   },
   "source": [
    "les exemples (presque totalement) faussess sont 0 , 1 , 5 , 7 , 8 , 9 , 10 , 11 , 15 , 17 , 19 , 21 , 24  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rKxr7MylCXQ1"
   },
   "source": [
    "*3ème formulation*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ByWj-1ucD0Le"
   },
   "source": [
    "les exemples (presque totalement) faussess sont 1 , 5 , 7 , 8 , 9 , 19 , 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uAJylqniD2bt"
   },
   "source": [
    "\n",
    "\n",
    "> =>\tOn constate  qu’il y a des exemples communs qui sont faux dans les différentes formulations , on peut assumer que ces exemples ( 1 , 5 , 7 , 8 , 9 , 19) sont les plus problématiques.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "r5PdWLR_jDua",
    "9aeuqdesknbY"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0dd989bb54be4933a509a05f180f1721": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "214eefac8d844530bc685d7353b943b5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2291cad5ca834e82823128fd731dbf48": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a020545bbde04b66858615616859dab3",
       "IPY_MODEL_2eb60b7eec314f2e8abc414155561de0",
       "IPY_MODEL_7c74ef3784dd41919840bae077d09fc4"
      ],
      "layout": "IPY_MODEL_a64b6664397245388ed2d8f1e542b2b8"
     }
    },
    "2eb60b7eec314f2e8abc414155561de0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_833eb72617dc4266a31523a6b9fb3b8f",
      "max": 1340622760,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3628971d57734ea4a048776d2a6ce88b",
      "value": 1340622760
     }
    },
    "3030f14c073a4d7dbc99dab13353d5bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ef70a1cb16ac4152adfb89fb5270c14c",
      "placeholder": "​",
      "style": "IPY_MODEL_e9b4adbbe5ab414e935fa5203e2a5866",
      "value": "tokenizer.json: 100%"
     }
    },
    "3628971d57734ea4a048776d2a6ce88b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3d1a4594028c4715a055c56dd2fe952e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d8ba93470f346ba82f165b421e368a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4d9cb57620694cb0b19a90b4b3335e9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4e1d49fbd6fe4a22827cd2ab52c827a0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f18df8990554ce8b6cf7a5635b5d3cd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "515e518eefe14a10af9ba8b70ebeff81": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56b0a5d7dd8644f5b27055ffab425e60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "581ab8f0c40948888318373606ea9dda": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6340d8ccf2ba4e05ab78e3e6302dc386": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7f318a83e8e74d679acedec78b6ff547",
       "IPY_MODEL_c5d894943d474c74a8fa6b79894d2c4e",
       "IPY_MODEL_b836175b71eb41019f0afe077841ff7c"
      ],
      "layout": "IPY_MODEL_6e7f11c9c3894db0a07d0134d0d5de5d"
     }
    },
    "6d99490a92324bcbaf65d668e7c1cdbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b26373edf4944cd69e8ae029883a955f",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b100b3a5cfbc45f2a73e1e41fa493991",
      "value": 466062
     }
    },
    "6e7f11c9c3894db0a07d0134d0d5de5d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7c74ef3784dd41919840bae077d09fc4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4e1d49fbd6fe4a22827cd2ab52c827a0",
      "placeholder": "​",
      "style": "IPY_MODEL_95cb059b3ffd42a983ca90cbbf1c5759",
      "value": " 1.34G/1.34G [00:11&lt;00:00, 174MB/s]"
     }
    },
    "7d1541aab1db423e8b435418b85f48b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c7c9bddc8dc6405b99d8fb17cd8d14be",
      "placeholder": "​",
      "style": "IPY_MODEL_0dd989bb54be4933a509a05f180f1721",
      "value": " 466k/466k [00:00&lt;00:00, 10.3MB/s]"
     }
    },
    "7f318a83e8e74d679acedec78b6ff547": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_90a9057c57a041c2a77eeb78ece1784f",
      "placeholder": "​",
      "style": "IPY_MODEL_3d8ba93470f346ba82f165b421e368a9",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "80305c3df04f48cc80d078a5948433a6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "833eb72617dc4266a31523a6b9fb3b8f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ce7b22d86214c56a0a6cd99ad81e43a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8eb1ef85d6a84ff1ae1b9dd3b59f609d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4f18df8990554ce8b6cf7a5635b5d3cd",
      "placeholder": "​",
      "style": "IPY_MODEL_bdb934d3b08f460e84d22cf4bb551c1f",
      "value": " 232k/232k [00:00&lt;00:00, 3.27MB/s]"
     }
    },
    "8f60f3770455407c903cf34a596e6862": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3030f14c073a4d7dbc99dab13353d5bb",
       "IPY_MODEL_6d99490a92324bcbaf65d668e7c1cdbd",
       "IPY_MODEL_7d1541aab1db423e8b435418b85f48b7"
      ],
      "layout": "IPY_MODEL_9fcf597ce0274d85bc804cdb730e1d56"
     }
    },
    "90a9057c57a041c2a77eeb78ece1784f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "92a382837778449c9ad2f3ef7a60ce6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ca3d47db30a140e8869c121ba6136cde",
      "max": 443,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_56b0a5d7dd8644f5b27055ffab425e60",
      "value": 443
     }
    },
    "9323ae14aac94cb093ae990032558e11": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "95cb059b3ffd42a983ca90cbbf1c5759": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9b5dee38103e4f44bea7176c265dfe80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_214eefac8d844530bc685d7353b943b5",
      "placeholder": "​",
      "style": "IPY_MODEL_4d9cb57620694cb0b19a90b4b3335e9e",
      "value": "vocab.txt: 100%"
     }
    },
    "9e34d59d3a8745b5b6e17f4140c437ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9f9b89917f2d45be9f933e15e605c0e5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9fcf597ce0274d85bc804cdb730e1d56": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a020545bbde04b66858615616859dab3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_581ab8f0c40948888318373606ea9dda",
      "placeholder": "​",
      "style": "IPY_MODEL_bf52b2b9fab6455aba21318aaeabb62a",
      "value": "model.safetensors: 100%"
     }
    },
    "a64b6664397245388ed2d8f1e542b2b8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "abaab5b1689448cfa46da6dc655b46e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_80305c3df04f48cc80d078a5948433a6",
      "placeholder": "​",
      "style": "IPY_MODEL_babdf51d945f4735959bfe1aa9964a62",
      "value": "config.json: 100%"
     }
    },
    "b100b3a5cfbc45f2a73e1e41fa493991": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b26373edf4944cd69e8ae029883a955f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3103a2d104843dea02dcb1dd556dbfb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9b5dee38103e4f44bea7176c265dfe80",
       "IPY_MODEL_f7cdc617504543eca85e7ad345624ae8",
       "IPY_MODEL_8eb1ef85d6a84ff1ae1b9dd3b59f609d"
      ],
      "layout": "IPY_MODEL_3d1a4594028c4715a055c56dd2fe952e"
     }
    },
    "b727dae935c4496a8e8cf8b852e99239": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b836175b71eb41019f0afe077841ff7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c51ce1f72b7f4d27a31b64d54f10c3c3",
      "placeholder": "​",
      "style": "IPY_MODEL_c11631fe6c5747589adf7a771c9417ce",
      "value": " 48.0/48.0 [00:00&lt;00:00, 2.02kB/s]"
     }
    },
    "babdf51d945f4735959bfe1aa9964a62": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bdb934d3b08f460e84d22cf4bb551c1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bf52b2b9fab6455aba21318aaeabb62a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c11631fe6c5747589adf7a771c9417ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c51ce1f72b7f4d27a31b64d54f10c3c3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5d894943d474c74a8fa6b79894d2c4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9323ae14aac94cb093ae990032558e11",
      "max": 48,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9e34d59d3a8745b5b6e17f4140c437ef",
      "value": 48
     }
    },
    "c63132b8139f4c9ab46aa438bbbe31b7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7c9bddc8dc6405b99d8fb17cd8d14be": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca3d47db30a140e8869c121ba6136cde": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df8bdb34f64d4b60867a77156edadea2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_515e518eefe14a10af9ba8b70ebeff81",
      "placeholder": "​",
      "style": "IPY_MODEL_b727dae935c4496a8e8cf8b852e99239",
      "value": " 443/443 [00:00&lt;00:00, 19.2kB/s]"
     }
    },
    "e9b4adbbe5ab414e935fa5203e2a5866": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ef70a1cb16ac4152adfb89fb5270c14c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f7cdc617504543eca85e7ad345624ae8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9f9b89917f2d45be9f933e15e605c0e5",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8ce7b22d86214c56a0a6cd99ad81e43a",
      "value": 231508
     }
    },
    "fe9dfd2bb9a04d4a876de27a31788a48": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_abaab5b1689448cfa46da6dc655b46e3",
       "IPY_MODEL_92a382837778449c9ad2f3ef7a60ce6a",
       "IPY_MODEL_df8bdb34f64d4b60867a77156edadea2"
      ],
      "layout": "IPY_MODEL_c63132b8139f4c9ab46aa438bbbe31b7"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
